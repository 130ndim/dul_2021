{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GrigoryBartosh/dul_2021/blob/main/Homework/hw8/Homework8_DRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "botyZAC03R1t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dul_2021'...\r\n",
      "remote: Enumerating objects: 281, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (118/118), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (64/64), done.\u001B[K\r\n",
      "remote: Total 281 (delta 68), reused 54 (delta 51), pack-reused 163\r\n",
      "Receiving objects: 100% (281/281), 53.75 MiB | 10.90 MiB/s, done.\r\n",
      "Resolving deltas: 100% (125/125), done.\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/geoffrey-hinton.jpg -> dul_2021/Homework/hw1/data/geoffrey-hinton.jpg\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/mnist.pkl -> dul_2021/Homework/hw1/data/mnist.pkl\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/mnist_colored.pkl -> dul_2021/Homework/hw1/data/mnist_colored.pkl\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/shapes.pkl -> dul_2021/Homework/hw1/data/shapes.pkl\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/shapes_colored.pkl -> dul_2021/Homework/hw1/data/shapes_colored.pkl\r\n",
      "dul_2021/Homework/hw1/data/hw1_data/smiley.jpg -> dul_2021/Homework/hw1/data/smiley.jpg\r\n",
      "Processing ./dul_2021\r\n",
      "\u001B[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\r\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001B[0m\r\n",
      "Building wheels for collected packages: dul-2021\r\n",
      "  Building wheel for dul-2021 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for dul-2021: filename=dul_2021-0.1.0-py3-none-any.whl size=23394 sha256=1f3f34ac07d801f84e94c009a895ad5264778fef555fe177d3d4eff599d476f3\r\n",
      "  Stored in directory: /private/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/pip-ephem-wheel-cache-qcb6ayp5/wheels/79/95/93/b6efc4fb97ff537f847a383bda2d2ef3cc8eaf618059843241\r\n",
      "Successfully built dul-2021\r\n",
      "Installing collected packages: dul-2021\r\n",
      "  Attempting uninstall: dul-2021\r\n",
      "    Found existing installation: dul-2021 0.1.0\r\n",
      "    Uninstalling dul-2021-0.1.0:\r\n",
      "      Successfully uninstalled dul-2021-0.1.0\r\n",
      "Successfully installed dul-2021-0.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!if [ -d dul_2021 ]; then rm -Rf dul_2021; fi\n",
    "!git clone https://github.com/GrigoryBartosh/dul_2021\n",
    "!unzip -qq dul_2021/Homework/hw1/data/hw1_data.zip -d dul_2021/Homework/hw1/data/\n",
    "!mv -v dul_2021/Homework/hw1/data/hw1_data/* dul_2021/Homework/hw1/data/\n",
    "!rmdir dul_2021/Homework/hw1/data/hw1_data/\n",
    "!pip install ./dul_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "fVjq5oAxztdb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions as dist, optim as opt\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZHWosWrbpO5Y"
   },
   "outputs": [],
   "source": [
    "from dul_2021.utils.hw8_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGaJ2yY4bGWo"
   },
   "source": [
    "# Question 1. KMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9puPlBKicfOq"
   },
   "source": [
    "## Notations from practice\n",
    "\n",
    "*   $p_{nu}(x)$ - pdf of numerator\n",
    "*   $p_{de}(x)$ - pdf of denominator\n",
    "*   $r(x)=\\frac{p_{nu}(x)}{p_{de}(x)}$ - density ratio\n",
    "*   $p_{nu}^*, p_{du}^*, r^*$ - estimatinos of respective functions\n",
    "*   $\\{x^{nu}_i\\}_{i=1}^{n_{nu}}$ - sample from numerator distribution\n",
    "*   $\\{x^{de}_i\\}_{i=1}^{n_{de}}$ - sample from denominator distribution\n",
    "\n",
    "\n",
    "\n",
    "## KMM objective\n",
    "\n",
    "Here we will implement Kernel Mean Matching (KMM) method for density ratio estimation. The basic idea of KMM is to 'match' expections of kernel function:\n",
    "\n",
    "$$argmin_{r^*} ||E_{p_{de}}r^*(x)K(\\cdot, x) - E_{p_{nu}}K(\\cdot, x)||$$\n",
    "\n",
    "Where $K(x, x') = exp(-\\frac{|x-y|^2}{2\\sigma^2})$. Emperical variant of this objective can be rewritten as follows:\n",
    "\n",
    "$$argmin_{r^*} \\frac{1}{n_{de}^2} (r^*_{de})^t K_{de, de} r^*_{de} - \\frac{2}{n_{nu}n_{de} }(r^*_{de})^t K_{de, nu}1_{n_{nu}}$$\n",
    "\n",
    "Where\n",
    "\n",
    "\n",
    "*   $r^*_{de}$ - vector with $(r^*_{de})_i=r^*(x^{de}_i)$\n",
    "*   $K_{de, de}$ - matrix with $(K_{de, de})_{i, j} = K(x^{de}_i, x^{de}_j)$\n",
    "*   $K_{de, nu}$ - matrix with $(K_{de, nu})_{i, j} = K(x^{de}_i, x^{nu}_j)$\n",
    "*   $1_{n_{nu}}$ - vector with $n_{nu}$ ones\n",
    "\n",
    "\n",
    "## You will provide these deliverables\n",
    "Density ratio on $[-2, 2]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.DataLoader(np.random.rand(5000), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.rand(10)\n",
    "m = torch.rand(10, 10)\n",
    "a = torch.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMM(nn.Module):\n",
    "    def __init__(self, hd=128, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self._r = nn.Sequential(nn.Linear(1, hd), \n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(hd, hd), \n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(hd, 1),\n",
    "                                nn.Softplus())\n",
    "        self._sigma = sigma\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._r(x[:, None])[:, -1]\n",
    "    \n",
    "    def _rbf(self, x, y):\n",
    "        return (-(x[:, None] - y).pow(2) / 2.0 / self._sigma).exp()\n",
    "        \n",
    "        \n",
    "    def fit(self, data_nu, data_de, batch_size=512, lr=1e-3, num_epochs=1000):\n",
    "        loader_nu = data.DataLoader(data_nu, \n",
    "                                    batch_size=batch_size, \n",
    "                                    drop_last=True,\n",
    "                                    shuffle=True)\n",
    "        \n",
    "        loader_de = data.DataLoader(data_de, \n",
    "                                    batch_size=batch_size, \n",
    "                                    drop_last=True,\n",
    "                                    shuffle=True)\n",
    "        \n",
    "\n",
    "        optim = opt.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        \n",
    "        bar = tqdm(range(num_epochs))\n",
    "        for epoch in bar:\n",
    "            acc_loss = 0.\n",
    "\n",
    "            for (b_nu, b_de) in zip(loader_nu, loader_de):\n",
    "                b_nu, b_de = b_nu.to(self.device), b_de.to(self.device)\n",
    "                \n",
    "                r_de = self(b_de)\n",
    "\n",
    "                loss = (r_de @ self._rbf(b_de, b_de) @ r_de) - 2 * (r_de @ self._rbf(b_de, b_nu)).sum()\n",
    "                loss /= batch_size ** 2\n",
    "                \n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                acc_loss += loss.item()\n",
    "            \n",
    "            bar.set_postfix_str(f'loss = {acc_loss / min(len(loader_nu), len(loader_de))}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "07hzT2JG2Lvv",
    "outputId": "303516fe-a460-438f-e3fd-649e6fbb9d29"
   },
   "outputs": [],
   "source": [
    "# distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "4-jdrQdePnCk"
   },
   "outputs": [],
   "source": [
    "def q1(data_nu, data_de):\n",
    "    \"\"\"\n",
    "    data_nu - An [n_nu] dataset with samples from numerator's distribution\n",
    "    data_de - An [n_de] dataset with samples from denominators's distribution\n",
    "\n",
    "    Returns\n",
    "    - a np.array with density ratios of np.linspace(-2., 2, num=100)\n",
    "    \"\"\"\n",
    "\n",
    "    model = KMM(64, 0.05)\n",
    "    model.to(DEVICE)\n",
    "    model.fit(data_nu.astype(np.float32), data_de.astype(np.float32), lr=1e-3, batch_size=512, num_epochs=1000)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(torch.linspace(-2.0, 2.0, 100, device=DEVICE)).cpu().numpy()\n",
    "        \n",
    "    return out\n",
    "    # your code goes here\n",
    "\n",
    "    # you need to calculate density ratio on x and return it\n",
    "    # x = np.linspace(-2., 2, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "4uSiYdu--V5G",
    "outputId": "b2ff12b4-ae92-4bca-9838-d331edefeecc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b953400b97f9422890551f28c92ec897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv5UlEQVR4nO3deXxb5Z3v8c8jW95lO97kfUmI1ziL8YSEEKAJobQwgVIYygDtdGNapoWZe1vKnXZa2s7c0g63dLgD7TDQS2iBUqBQaCmlkKQlLCFOSJzEsbPZSZx4kZ14X2U9948jJY7jRU4kHVn6vV8vvyJZR+f8dOJ88/g5z3kepbVGCCFE8LKYXYAQQojpSVALIUSQk6AWQoggJ0EthBBBToJaCCGCXKQ/dpqWlqYLCwv9sWshhAhJ27dv79Bap0/22oxBrZQqAZ4b9635wLe11j+Z6j2FhYXU1NTMtk4hhAhbSqkjU702Y1BrrRuApe4dRQDHgZd8VZwQQojpzbaPei1wSGs9ZfILIYTwrdkG9aeAZyd7QSl1p1KqRilV43A4LrwyIYQQAChvbyFXSkUBJ4AKrXXbdNtWV1dr6aMWInSMjo7S3NzM0NCQ2aXMeTExMeTm5mK1Ws/6vlJqu9a6erL3zGbUx8eAHTOFtBAi9DQ3N2Oz2SgsLEQpZXY5c5bWms7OTpqbmykqKvL6fbPp+riVKbo9hBChbWhoiNTUVAnpC6SUIjU1dda/mXgV1EqpeGAd8JvzqE0IEQIkpH3jfM6jV10fWut+IHXWexeha7ALdjwFegyscWDLgtLrwCI3uwrha/KvSsye1vDKV+BP/wJv3g9/uBd+fQds/anZlQnhlc2bN3Pddded9/u7urp49NFHTz8/ceIEN910ky9Km5QEtZi9updh36uw9jvwzVa4txEWfhQ2/ht0HTO7OhHGxsbGfLYvp9M55WsTgzo7O5sXXnjBZ8eeSIJazE5/B/z+a5BdBZfeDdZYiEuBax8ENLz2daPFLYQPNTU1UVpaym233UZZWRk33XQTAwMDgDFlxTe+8Q2qqqp4/vnneeONN1i5ciVVVVXcfPPN9PX1AfD6669TWlpKVVUVv/nN5JfbnnzySdavX8+aNWtYu3YtfX19rF27lqqqKiorK/ntb38LwH333cehQ4dYunQpX//612lqamLRokWAceH1s5/9LJWVlSxbtoxNmzZd8Of3y6RMIoT94V4Y6obrH4GIcT8+yfnwkX+GN74F+16B8uvNq1H41Xdf3UvdiR6f7rM8O5Hv/HXFtNs0NDTwxBNPsGrVKj73uc/x6KOP8rWvfQ2A1NRUduzYQUdHBzfeeCNvvvkm8fHx/PCHP+THP/4x9957L1/84hfZuHEjF110EbfccsuUx9mxYwe1tbWkpKTgdDp56aWXSExMpKOjgxUrVrB+/XoeeOAB9uzZw86dOwHjPxKPRx55BKUUu3fvpr6+nquvvpr9+/cTExNz3udHWtTCewfehD0vwhXfAHv5ua9f8mXIXAyvucNcCB/Ky8tj1apVANx+++1s2bLl9Gue4H3//fepq6tj1apVLF26lA0bNnDkyBHq6+spKipi4cKFKKW4/fbbpzzOunXrSElJAYxxz//8z//M4sWLueqqqzh+/DhtbdPfSrJly5bT+y8tLaWgoID9+/df0GeXFrXw3o4NkGCHy/5x8tcjIuHaH8MTV0Htr2H5FwNangiMmVq+/jJxWNv45/Hx8YARrOvWrePZZ8++5cPT8vWGZ18ATz/9NA6Hg+3bt2O1WiksLDTl7kxpUQvvDPfBgTeMLo0I69Tb5f0VpJVA3W8DV5sIC0ePHuW9994D4JlnnuGyyy47Z5sVK1bwzjvvcPDgQQD6+/vZv38/paWlNDU1cejQIYBzgnwq3d3dZGRkYLVa2bRpE0eOGPPR2Ww2ent7J33P6tWrefrppwHYv38/R48epaSkZHYfdgIJauGd/a+Dcwgqbpx52/Lr4cg70CeTcwnfKSkp4ZFHHqGsrIxTp07x5S9/+Zxt0tPTefLJJ7n11ltZvHgxK1eupL6+npiYGB577DGuvfZaqqqqyMjI8OqYt912GzU1NVRWVvLUU09RWloKGH3iq1atYtGiRXz9618/6z133XUXLpeLyspKbrnlFp588kmio6Mv6LN7PSnTbMikTCHoV7fB8e3wT3Uz39TSthd+eilc9xBUfy4w9Qm/2rdvH2VlZaYdv6mpieuuu449e/aYVoMvTXY+p5uUSVrUYmZDPXDgT1B+w+mQ3tzQzid/+i5NHf3nbp9RDqkXwd6XA1qmEKFKglrMrOEPMDYMi4xuj4bWXv7h6R1sP3KKLzxVQ+/Q6NnbK2V0fzRtMcZdC3GBCgsLQ6Y1fT4kqMXM9r4EibmQU01n3zCf37CNuOhIHrplCY0d/fzTc7twuSZ0oZXfYMwDUv87U0oWIpRIUIvpDXbBwTeh4gaGXZov/XI7jt5h/vvT1XxiWS7/cm0Zb+5r4ydvThgnmlkJ84pk9IcQPiBBLabX8Bq4RqHiRp7bdoxtTaf40U2LWZqXDMBnLi3kb6pzeXjjQd6sG3cjgFJQcQMc/jMMnDSldCFChQS1mN6hTcZNLjlVbD18kpzkWK5fmnP6ZaUU379hERXZiXzthV2c6Bo8896y9Ub3x/4/mlC4EKFDglpM7+h7kL8SlGL7kVNUFcw7Z5PoyAj+82+rGHW6uOdXH+IccxkvZC2FmGQ4+m5ASxahZ+JsdWZpamrimWeeOf28pqaGu+++2+/HlaAWU+s6Bt3HoOBSTnQN0tozxMX5yZNuWpQWz799opJtTaf4j7cOGN+0WCB/BRx9P3A1i5A0XVBPNx3p+ZhufxODurq6mocfftinx5+MBLWYmidg81ew/cgpAC4uSJly8xuW5XDzxbn856aDfNB48vR76dgvw/TEBZk4rejmzZtZvXo169evp7y8/KxpRgEefPBB7r//fgAOHTrENddcw8UXX8zq1aupr68/Z//3338/d9xxB6tWreKOO+6gqamJ1atXU1VVRVVVFe++++7pOt5++22WLl3KQw89dNYCBCdPnuSGG25g8eLFrFixgtraWp99fpmUSUzt6LsQnQj2RWzfVk+M1UJplm3at3z3+grePdTJt17eze/vXo01f6XxwrGtUHptAIoWfveH+6B1t2/3mVkJH3tgypcnTiu6efNmduzYwZ49eygqKjprmtGJ7rzzTn72s5+xcOFCtm7dyl133cXGjRvP2a6uro4tW7YQGxvLwMAAf/rTn4iJieHAgQPceuut1NTU8MADD/Dggw/yu9/97nQdHt/5zndYtmwZL7/8Mhs3buTTn/70rCaDmo4EtZjakfcgbzlYIvjw6CmW5CZjjZj+l7C4qEi+u76CLzxVw8+3NPL3q5ZBRLTR1y1BLXxo+fLlFBUVTbtNX18f7777LjfffPPp7w0PD0+67fr164mNjQVgdHSUr3zlK+zcuZOIiAivpindsmULL774IgBr1qyhs7OTnp4eEhMTvf1IU/IqqJVSycDjwCJAA5/TWr93wUcXwWvgJDj2QeVNDI6MsfdED3dePt+rt15VbueqMjs/efMA1y3JJienSvqpQ8k0Ld9AGj8daWRkJC6X6/Rzz1SkLpeL5ORkr1q24/f30EMPYbfb2bVrFy6X64Im/fcFb/uo/wN4XWtdCiwB9vmvJBEUPMFacCm1zV04XZqLJxnxMZX715ej0Xzv1b1GP/WJnTAy4J9aRcibblpRALvdTnt7O52dnQwPD5/umkhMTKSoqIjnn38eMOar3rVr14zH6+7uJisrC4vFwi9+8YvTazF6O73p5s2bSUtL80lrGrwIaqVUEnA58ASA1npEa93lk6OL4HX0XYiIguwqdhztAmBZvvdBnTsvjrvXLuSPe9vYF1lh3DRzYoefihWhbrppRQGsVivf/va3Wb58OevWrTs9HSkYk/8/8cQTLFmyhIqKitPrHk7nrrvuYsOGDSxZsoT6+vrTre3FixcTERHBkiVLeOihh856z/3338/27dtZvHgx9913Hxs2bLjAT33GjNOcKqWWAo8BdRit6e3APVrr/gnb3QncCZCfn3+xZ4JtMUf991pjgYDPvc4XNtRw2NHHxq9dOatdDDvHqP7+m9xUkcB36j4Oa74Fl5/7j0wEP7OnOQ01/pjmNBKoAn6qtV4G9AP3TdxIa/2Y1rpaa12dnp4++8pF8Bjph5adkL8SrTU7jk5+o8tMoiMjuKIknVf3D6IzyqWfWojz5E1QNwPNWuut7ucvYAS3CFXNNeByQsGlHOkc4GT/yKz6p8dbV26no2+YjpQqOPYBuMZ8XKwQoW/GoNZatwLHlFKeRb/WYnSDiFB19H1AQd7y0ze6VM2if3q8K4sziLQo3nMWw3CPsfqLmJP8sRpUODqf8+jtqI+vAk8rpWqBpcD/nvWRxNxxYgekl0JMEjuPdZEQHcnCjITz2lVSnJXlRSk815ptfOPY1unfIIJSTEwMnZ2dEtYXSGtNZ2fnrIf7eTWOWmu9E5i0k1uEoJZdUHQFALuPd7MoJxGLRZ337taV2/nuqx2MzUslomWnj4oUgZSbm0tzczMOhyxYfKFiYmLIzc2d1XvkzkRxtr526G2BrCWMjrmoa+nhMysLLmiXV5XZ+e6rdbTEFpPbMvMYVhF8rFbrjHcBCv+RSZnE2VrcE8lkLWZ/Wy8jTheVuckXtMu8lDhKM21sG86D9npwjlx4nUKEEQlqcTZP10RmJXuOdwNQmZN0wbtdV27nra5M48YXh9zYKsRsSFCLs7XsMtY6jEmitrkbW0wkBSlxF7zbdeV29rgKzhxDCOE1CWpxttZayFoCGBcSK3OSLuhCosei7CTaI7MZtsSd6V4RQnhFglqcMXgKTjVB1hJGnC7qW3p90u0BYLEoLrIn0hg53/jPQAjhNQlqcYZnMnjPhcQxF5W5vglqgGK7jZ3OfOM4coeiEF6ToBZneLokMpew24cXEj2K7QnUDOfB6AB0HvLZfoUIdRLU4oyWXZCYAwnp1DZ3kxgTSb4PLiR6LLTb2ONyj8WV7g8hvCZBLc5o2QWZiwHYfbyLytwklLrwC4keJXYbB3U2Y5aoM8MAhRAzkqAWhpF+6DwAWUsYdo7R0NpLZU6yTw+RlRRDbHQMrdFFMvJDiFmQoBaGtr2gXZC1hIbWXkbHNIt9eCERQCnFQnsC9RQZXR8ywY8QXpGgFgbPTShZi/1yIdGj2G5j61CuMRSwu9nn+xciFElQC0PLLohNgcQc9hzvJinWSu68WJ8fpthuY9tQ3pljCiFmJEEtDG17IXMRKEXdiR4qshN9eiHRo9huY5/ORyuLjPwQwksS1AJcLnDUQ0YFzjEX9a29lGf5Zpn7iYrtCQwRTU9sHrTLQkFCeEOCWkDXEeMmlIwyGjv6GXa6qMjxT1Cn26JJjrNyLLIQ2mUWPSG8IUEtzgRmRjl7T/QAUJ7l+wuJYIz8KM6wUTeWAycPw+igX44jRCiRoBZnuiDSS6hr6SEq0sL89Hi/Ha44M4Gt/XZjOGDHfr8dR4hQIUEtjKBOyoeYROpO9FBit2GN8N+PRrHdxs5h92K30v0hxIy8WjNRKdUE9AJjgFNrLQvdhpL2fWAvR2tNXUsP68rsfj3cwgwbR7Qdl8WKRS4oCjGj2Sxu+xGtdYffKhHmcI4Y3Q/FH6WtZ5iT/SOUZ/vnQqJHsT0BJ5GciiskVVrUQsxIuj7C3clD4HJCRjl1LcYdif4O6tSEaNISojgSUSBdH0J4wdug1sAbSqntSqk7/VmQCDBP10NGGXXuER9lfhpDPV6x3cYeZw50H4OhHr8fT4i5zNugvkxrXQV8DPgHpdTlEzdQSt2plKpRStU4HA6fFin8qK0OVASkFVPX0kNhahwJ0bPpETs/xXYbW3vdfeGOer8fT4i5zKug1lofd//ZDrwELJ9km8e01tVa6+r09HTfVin8p30fpF4EkdHUnejxe7eHx0J7ArtGPSM/5IKiENOZMaiVUvFKKZvnMXA1sMffhYkAaa+DjDJ6h0Zp6hzw263jE5XYbRzXaTgj46SfWogZeNOitgNblFK7gA+A32utX/dvWSIgRvqNVcczyqlv7QX8fyHRY6HdhsZCZ+x8aVELMYMZOyO11oeBJQGoRQSaox7QZ11I9Net4xMlxVqxJ0bTZMnH3r4tIMcUYq6S4XnhbNwcH3UnekiJj8KeGB2wwxfbbdSOZkO/A/rkArQQU5GgDmft+yAyBlKKqGvx3xzUUym223i3N8N44pB+aiGmIkEdztrrIK2YUa1oaPPfHNRTKbYnsGc0x12LBLUQU5GgDmeOBsgo57CjnxGnK2AXEj2K7TYcJDMSlWysMCOEmJQEdbga6oGe4+6pTd23jge4Rb3QbgMUjpgime5UiGlIUIcrTzCml1J3oofoSAtFaf6bg3oyCdGR5CTH0qhyja4PrQN6fCHmCgnqcOW5bdu9WEBppo1IP85BPZViewK7RzJhqMsY/SGEOIcEdbhq3wcR0ejkAvYG8NbxiYw5PzwjP2TODyEmI0EdrhwNkFZMS+8oXQOjAe+f9lhot1Hn9Mz5IUEtxGQkqMOVo8Ho9vDckWhSi7rEbqOdZEatNmlRCzEFCepwNNwH3UeNC4ktPSgFpZnmBPVFGQkopXDEFBr/eQghziFBHY5Oj/gwWtRFqfHEB2AO6snERkWQnxJHo8qTFrUQU5CgDkeelmtGGXUtPZSZ1O3hUWy3UTucCQMd0C/LcgoxkQR1OHLUg8VKT1wuR08Gbg7qqRTbE/igz73YhHR/CHEOCepw5GiAtIXUtw0C5l1I9Ci222gYc8/5Id0fQpxDgjocOerd/dPGreMVJreoSzJtnCDVWO1FWtRCnEOCOtyMDhqruqSXsvdED2kJUaTbAjcH9WTmpyUQabHQHlMkLWohJiFBHW46DgD69K3jZVmBnYN6MlGRFgrT4mkkV1rUQkxCgjrcuFusoynF7G/rpSI7MEtvzaTEM/KjrxUGT5ldjhBBRYI63DjqQUVwwGlndEybfiHRo9huY9uAZ84PmfJUiPG8DmqlVIRS6kOl1O/8WZDwM0cDpC5gr3vER0WQBHVJZgL7XTLyQ4jJzKZFfQ8g6yXNdZ4RHy09xFojKEwN7BzUU1lot3Fcp+G0xEg/tRATeBXUSqlc4Frgcf+WI/zKOQwnD0N6GXtP9FCWZSPCYu6FRI+ClDiskZE4YgpkoVshJvC2Rf0T4F7A5b9ShN91HADtQqeXsM/EOagnExlh4aL0BGO1F2lRC3GWGYNaKXUd0K613j7DdncqpWqUUjUOh6zUEZTcfb+tUYX0DjuDZsSHR0mmjV1DWcZajkM9ZpcjRNDwpkW9ClivlGoCfgWsUUr9cuJGWuvHtNbVWuvq9PR0H5cpfMLRAMrC7qE0IPCL2c5koT2B7YN244m0qoU4bcag1lr/L611rta6EPgUsFFrfbvfKxO+56iHlPnsbhsmwqIoybSZXdFZSuw2DmgZ+SHERDKOOpw46k+vOr4gPZ4Ya4TZFZ2l2G7jmM7AaYmWoBZinFkFtdZ6s9b6On8VI/zIOQKdhyC9hL0neoKufxogJzmW2Cgrjuh86foQYhxpUYeLk4dAj9FrW0Brz1DQ9U8DWCyKi+w2DpErLWohxpGgDhfu4Dugc4HguSNxolK7jV3DmdB9DIZ7zS5HiKAgQR0u2usBxfZ+94iPIA3q4kwbu4YyjScdMueHECBBHT4c9TCvkN1tI+Qkx5IcF2V2RZMyRn4YrX7jPxchhAR1uHA0uBcL6KYsCPunPUoybRzVGTgtUdJPLYSbBHU4GBuFzoOMphZzuKM/aPunAdISokiKj8URlScjP4Rwk6AOBycPg2uU5sgCtIZFOcE3NM9DKUWxPcHo/pDJmYQAJKjDg7sLoW40CwjeER8epZmJ7By0Q9dRGOk3uxwhTCdBHQ7cXQjv9aQyL85KVlKMyQVNr9huY68z23giIz+EkKAOC456SC5gZ9sIFdlJpi9mO5OSzAQZ+SHEOBLU4aC9Hld6Cftb+4K+2wOMFvURbWdMRcrIDyGQoA59Y6PQsZ+TsfMZGXMF7Y0u49lirGQmJ9AWlSdBLQQS1KGv8xC4RjlkyQcIysmYJlNsT2C/Kw/a68wuRQjTSVCHOnfQfTiUTaw1gqK04FjMdiYlmYnsGMoyRn7InB8izElQh7r2OlARvH0qhfLsxKBZzHYmJZkJ1I3JBUUhQII69LXvQ6cuYGfL4Jy4kOhRbLfRcHrkh3R/iPAmQR3q2usYSCqmf2RsTgX1gvQEWlQGI5ZYCWoR9iSoQ9lIP5xspDmqEJg7FxIBYqwRFKQmcNxaIEEtwp4EdShzNACaurFcIi2KhfYEsyualdLMRPaO5UKbBLUIbxLUoczdEn2v185Cu43oyOBazHYmJZk2Y+THQAf0OcwuRwjTSFCHsvZ96MgYNrfHzan+aY/STBv1rjzjSftec4sRwkQzBrVSKkYp9YFSapdSaq9S6ruBKEz4QHsdzpRi2vvHqAziqU2nUpqZaNz0AtAuU56K8OVNi3oYWKO1XgIsBa5RSq3wa1XCN9rqcMTOB2BRztxrUefOi2UwKoX+yGRokxa1CF8zBrU29LmfWt1f2q9ViQs3cBL6Wjmo8lGKoF5+ayoWi6I400ajpUBa1CKsedVHrZSKUErtBNqBP2mtt06yzZ1KqRqlVI3DIRd+TOcOtu2DWcxPiycuKtLkgs5PaWYitSPZ6PZ94HKZXY4QpvAqqLXWY1rrpUAusFwptWiSbR7TWldrravT09N9XKaYNfeIj02nUoN66a2ZlGbaqB3NQY32Q9cRs8sRwhSzGvWhte4CNgHX+KUa4Tvtdbiik6jtiWfRHLrRZaKSTBsNckFRhDlvRn2kK6WS3Y9jgXWAzJIT7Nrq6E1cCCgq5uCFRI/STBv7T8/5IRcURXjypkWdBWxSStUC2zD6qH/n37LEBdEa2vdxzFoAzK1bxydKjovCljiPTmumtKhF2JrxCpPWuhZYFoBahK90HYXhbnY788lPiSMp1mp2RRekNMvGgeN5pMoQPRGm5M7EUNRaC8Cfe7Lm5PjpiUoybWwfzkV3HIDRQbPLESLgJKhDUetutLKwuSt9Tnd7eJRlJlI7VoDSYzJBkwhLEtShqKWWwcT5DBE9p4fmeZRk2tirC40nrbtMrUUIM0hQh6LW3ZyIWQgwJydjmmhBegKtKoOhiARo3W12OUIEnAR1qBk4CT3N7HUVkJUUQ1pCtNkVXbCoSAsL0m00Rc6HllqzyxEi4CSoQ437QuI7/dkh0T/tUZZl48PRfGNyJteY2eUIEVAS1KHG3eJ861RGSIz48KjITmLbUC44B6HzoNnlCBFQEtShpnU3w3FZdOpEFueGTou6IjvxzAVF6f4QYUaCOtS01tIWZ1xIrMxJNrcWHyrPTuSQzsapomTkhwg7EtShZHQQOvZTpwvJTooh3Tb3LyR6JMdFkTnPxvGoQmlRi7AjQR1K2upAu3i3P5vKEOr28KjITmT3WIExRE/L2hUifEhQhxL3iI+N3Zkszk02txY/qMhO4v3BXBg8CT3HzS5HiICRoA4lrbU4rTaadfqcXMx2JotyEqlzGTMCSveHCCcS1KGkdTft8cWACsmgrshOol7no1Gnf3sQIhxIUIcK1xi07aWeAvJT4pgXH2V2RT6XYYsmLiERR1Se3EouwooEdahw1MPoAFv680LyQiKAUoqK7CTqdCG0yBA9ET4kqENFcw0AG/vyWRyC3R4eFdmJvDuYD93HoLfN7HKECAgJ6lBxvIbRqGSadGbItqjB6KeuGbvIeHK8xtxihAgQCepQ0bydE/HlgAqJOainsijHuJXcpSJP/xYhRKiToA4Fw33g2McufRHz0+JJjJnbayROJ29eHFHRcbTELIDmbWaXI0RAzBjUSqk8pdQmpVSdUmqvUuqeQBQmZuHEh6BdbOrLD6mJmCZjsSjKshPZxULjc8uUpyIMeNOidgL/U2tdDqwA/kEpVe7fssSsuPtqN/XlURmCdyROVJmTxOa+fBjpM0a7CBHiZgxqrXWL1nqH+3EvsA/I8XdhYhaaa+hPKKALG8vyk82uxu+W5CXzgXOB8UT6qUUYmFUftVKqEFgGbJ3ktTuVUjVKqRqHw+Gj8oRXjm+nMbqUqAhLSKyROJNlecbolmFrkoz8EGHB66BWSiUALwL/qLXumfi61voxrXW11ro6PT3dlzWK6XQfh94Wto4UUZGTSHRkhNkV+V3uvFhS46NpjC6VFrUIC14FtVLKihHST2utf+PfksSsuFuUfziVy7K8eSYXExhKKZbkJbN1dD6074PhXrNLEsKvvBn1oYAngH1a6x/7vyQxK801uCxR1DrzqCpINruagFmal8zG3nxAw/EdZpcjhF9506JeBdwBrFFK7XR/fdzPdQlvHd9Op62EEawsyw+PFjUYQb3T5b6gKP3UIsRFzrSB1noLoAJQi5itMSec+JC6hI+RYYsmOynG7IoCZkluMt0kcCq2gHnN280uRwi/kjsT57LWWhgd4M8DBSzLT8bopQoPSXFW5qfFUx9RDM0fyNJcIqRJUM9lTVsAeLV7AVVh1O3hsTQvmU2D86HfAZ0HzS5HCL+RoJ7Lmt6m31aEg3lh1T/tsSQvmTcGio0njX82txgh/EiCeq4ac8KR9zgQt4xIS2guvTWTpe4bXwZj7dD4ttnlCOE3EtRzVcsuGOnlLyMllGUlEhsV+je6TFSWlUhURAQH46qMbiDppxYhSoJ6rmr6CwAvdBaGxfwek4mKtFCencjbzjIY6DBufhEiBElQz1VNWxhKvoijI7awvJDosTQvmRdPFhlPmqT7Q4QmCeq5aGwUjrzH4YQqAC6Zn2JyQea5pCiFQ6OpDCfkQuNfzC5HCL+QoJ6LTuyE0X7+PFJKQWocWUmxZldkmkvmpwJwKH4ZHHkHXC6TKxLC9ySo5yJ3//Rz7flcUhS+rWmAlPgoSjNt/HmkFAZPQdses0sSwuckqOeipi0MzSuhaSiOFe4WZThbuSCVZx2FxhPp/hAhSIJ6rnGOwNH3OZywDDjzq384Wzk/laPOeQzZCuSCoghJEtRzTfMHxvweI2XkpcSSkxy+/dMelxSlohQciK+CI+8aNwMJEUIkqOeahj+gI6L4ZXsRlxRJaxqMCZoqshN5Y6gChnvg6HtmlySET0lQzyVaQ/3v6c9exfHBSOmfHmfl/FR+4bgIHRENDa+ZXY4QPiVBPZc4GuBUI7sTLgUI+xEf462Yn0rXWBRd9pVQ/3u5nVyEFAnqucTdUnx1cDE5ybHkpcSZXFDw+KuiFCwKtsWshK4j0F5ndklC+IwE9VzS8Bo6ayl/PBYR1ncjTiYxxkplThK/7lkEKKiX7g8ROiSo54reNmiuoTP3Kjr7R1ghFxLPsWJBKptPWBjLvhgafm92OUL4jAT1XHHgj4Bmo64G4PLidHPrCUJrS+04XZr9yZfDiQ+h+7jZJQnhEzMGtVLq50qpdqWU3JtrpvrXICmfXx9NZFFOIplhtJCtty4umEdaQhTP9y82viGjP0SI8KZF/SRwjZ/rENMZGYDDmxhacDU7jnWxptRudkVBKcKiWFeeyXONMbhSFkhQi5AxY1Brrf8CnAxALWIqB/4IziG2Ra/ApeGqsgyzKwpa1yzKpH/ExbGMjxjLcw12mV2SEBfMZ33USqk7lVI1Sqkah8Phq90KgA+fhsQcnusoJN0WzaLs8Fsf0Vsr56dii4nkpZFLwDUKe140uyQhLpjPglpr/ZjWulprXZ2eLhe6fKb7OBx6i7HFt/Ln/SdZU5KBxaLMripoRUVaWFuawYbGJLR9Eex4yuyShLhgMuoj2O16FrSLnakfp3fYyRrp9pjRNYsyOTXopDH/RmjZCa27zS5JiAsiQR3MtIYPfwmFq3nteCxRkRYuuyjN7KqC3uXF6cRYLfx6aCVERMOOX5hdkhAXxJvhec8C7wElSqlmpdTn/V+WAIwpO081wrLb2Vjfzsr5qcRHR5pdVdCLi4rkiuJ0Xm4YRJdeB7XPweiQ2WUJcd68GfVxq9Y6S2tt1Vrnaq2fCERhAqM1HWXjUNpaGjv6WSvdHl77eGUWrT1D7M28Hoa6oP53ZpckxHmTro9gNdQDdS9D5Sd5YXcnFgVXl2eaXdWc8dGKTFLio3ikMRuS8+WiopjTJKiD1c5nYHQA55Lbeb6mmTWldrkbcRZirBH8TXUeb9Q76C37FDT+GToPmV2WEOdFgjoYjQ7BOz+Bgst4syeXjr5hbl2eZ3ZVc85tl+Tj0pqnR6+EyBh4+/+YXZIQ50WCOhjteAp6W+DKb/DMB8fISorhCpmEadbyUuJYU5LBE7sGGav6LOz6lbSqxZwkQR1snMOw5SHIX8mxxIt5+4CDm6vziIyQv6rzcfvKAhy9w7yVeitEWOEvD5pdkhCzJv/6g82Hv4DeE3DFN/j19mYAbvkr6fY4X1csTCc/JY7Hdw5A9eeNoXrSqhZzjAR1MHGOwNsPQe5ynAWX8+uaY1xZnE5OcqzZlc1ZFovi9hX5fNB4kj1FfwcRUdKqFnOOBHUw2fY49DTDld/g9bo22nqG+dTyfLOrmvNuXZ5Pui2af3nLga7+HNT+ylgoWIg5QoI6WJxshI3fh4VXM1xwJT96vYESu421pXKTy4WyxVi596MlfHi0i9eSb4HoRPjtV8A1ZnZpQnhFgjoYuFzwylfBEgnX/YQN7x3h6MkBvnVdmVxE9JFPVuWyJDeJ7210MLTuAWj+AN5/1OyyhPCKpEAw2PEkNL0NV3+fzog0/u9bB/lISTqrF8qQPF+xWBTfWV9BW88wD7cvhZJrYeO/QscBs0sTYkYS1GbrOgZvfBuKroCqz/CTNw8wMDrGN68tM7uykFOVP48bl+Xw+JYmDl/yPeMmmJfvki4QEfQkqM001A3P3gpoWP8wDW19PPPBUW67JJ+LMmxmVxeS7vtYKYmxVj774jH61/7A6AJ541vGlLJCBCkJarM4h+G528GxD27eQHd0Dl/65XaSY63cs3ah2dWFrIzEGP7rjotp6Rri8zsKGVv+90Zf9Ts/Mbs0IaYkQW0Glwte+hI0/gWufwTn/DX8wzM7aD41wM/uuJjUhGizKwxpFxfM44c3VfJ+4ym+PXQbetFN8Ob9MsOeCFoyC32gjQ7Cq/fA3t/AVd+FJZ/iX1/Zy5aDHfzok4v5q8IUsysMC59Ylsv+tj5+uvkQMSu+yjcXnMLy6j3Gi1WfNrc4ISaQoA6kU0eM7o7WWvjItxhbeTf/8UYDT77bxBcuK+Jv5FbxgPr61SUMj7p44p1GGuffzX/lO7G+8lVo3gYf+3ewyrSyIjhIUAeC1rDvVXj1bqPb49bnOJm7hnue3MbbBzr4ZFUu/+vjMsoj0CwWxbf/upyyLBvffGkPVyV+lWcqF5Gz4xFo2QU3Pg7pxWaXKYT0UfvdsQ/g59fAr++AxBz0FzfylmsZ1z78NlsbT/KDGyt58ObFRFiU2ZWGrZur83ju71cw6rKwatsqHs74PmOdTfDoCuNGpJ4TZpcowpzSfhiWVF1drWtqany+3zljZADqfw+7noFDGyHBjvOK+/i9ZS0/ffsI9a29FKbG8Z9/W8WinCSzqxVuQ6Nj/L93mnh080Gih0/yg7Q3WNv3CioiErX4Flh8C+SvBIu0b4TvKaW2a62rJ33Nm6BWSl0D/AcQATyutX5guu3DLqhdLuhogCPvGCuH738DRnoZTcihPvsTPOH8GG8d6qd32MnCjAS+fOUC/npJNla5PTwoneof4fEth/nNjuNE9Bzjn6Je5jrLe0TrIYbjs7GUfAzr/FVGaCdmm12uCBEXFNRKqQhgP7AOaAa2Abdqreumek9IBLXWxlhn5yB6uBfnQA/OwW6cPW04e9pw9bSgTjViPXWI2N5GIp0DAHRHpPJB5DKeGljJltESNBYyE2O4siSdj1ZkckVxOhbp5pgTXC7N1saTvFp7gp0Hm1l46i/cEPEOl1jqiVPDAPREpNAVV8CgrZCxxDyUzU5EYiZWWzpR8UlExydjjUskOiaOqKho+bsXU5ouqL25mLgcOKi1Puze2a+A64Epg/p8Hfj+xVj18CSv6GmfeqgpNlJo1MTnWmPBhQUXCuNxJE4iGSMSJ1HaiUXp0/u1ur88XFpxglQOu7I4pFdTpwv4UJUzGldAfmo8JXYb6zNtLM5NptiegFLyD3SusVgUKxeksnJBKlBJZ98ath85xYbWUwwfryWpvYa0wUNkdTdT2PMWaSd6pt2fU1sYwoqTCMaIYEx5fgIj3D+FChcWUOf8tI7by5nHXnVays9dQA1EJFH+zXd8vl9vgjoHODbueTNwycSNlFJ3AncC5Oef3xzK3fFFWFwj3m087gdw/I+inhDXZ/+gGo+1sgAWtAJUBBoLWllwWSLRKhKXsjIWEY3L/eW0JuCKsjFmTcAVl4aOt6PiU0mIiyExxsrq2Eg+kRBNUqxVAjmEpSZEc3VFJlRkAmXALQBorekeHKWpp4eBk62MdLcw2tuBa6gHhnphpA/GhsE5hHIOo7QTNTaKcjkBF2gXSruM3+K0EdkaUFrjieMzzz0mj+mzvhsyt8XPnc/htCb6Zb8+G56ntX4MeAyMro/z2Uf1/3jBV+UIETBKKZLjokiOS4PMNGCR2SWJEOPN1azjwPg7MXLd3xNCCBEA3gT1NmChUqpIKRUFfAp4xb9lCSGE8Jix60Nr7VRKfQX4I8bwvJ9rrff6vTIhhBCAl33UWuvXgNf8XIsQQohJyB0XQggR5CSohRAiyElQCyFEkJOgFkKIIOeX2fOUUg7gyHm+PQ3o8GE5viJ1zY7UNTtS1+yEYl0FWuv0yV7wS1BfCKVUzVQTk5hJ6podqWt2pK7ZCbe6pOtDCCGCnAS1EEIEuWAM6sfMLmAKUtfsSF2zI3XNTljVFXR91EIIIc4WjC1qIYQQ40hQCyFEkDM9qJVS/66UqldK1SqlXlJKJU+x3TVKqQal1EGl1H0BqOtmpdRepZRLKTXlcBulVJNSardSaqdSyu8LRc6irkCfrxSl1J+UUgfcf86bYrsx97naqZTy23S5M31+pVS0Uuo59+tblVKF/qpllnX9nVLKMe4cfSEANf1cKdWulNozxetKKfWwu+ZapVSVv2vysq4rlVLd487VtwNUV55SapNSqs79b/GeSbbx7TnTWpv6BVwNRLof/xD44STbRACHgPlAFLALKPdzXWVACbAZqJ5muyYgLYDna8a6TDpfPwLucz++b7K/R/drfQE4RzN+fuAu4Gfux58CnguSuv4O+M9A/Ty5j3k5UAXsmeL1jwN/wFjLbgWwNUjquhL4XSDPlfu4WUCV+7ENY/HviX+PPj1npreotdZvaK2d7qfvY6wgM9HpBXa11iOAZ4Fdf9a1T2vd4M9jnA8v6wr4+XLvf4P78QbgBj8fbzrefP7x9b4ArFX+X/DSjL+XGWmt/wKcnGaT64GntOF9IFkplRUEdZlCa92itd7hftwL7MNYW3Y8n54z04N6gs9h/C800WQL7E48MWbRwBtKqe3uBX6DgRnny661bnE/bgXsU2wXo5SqUUq9r5S6wU+1ePP5T2/jbih0A6l+qmc2dQF80v3r8gtKqbxJXg+0YP73t1IptUsp9QelVEWgD+7uMlsGbJ3wkk/Pmc8Wt52OUupNIHOSl76ptf6te5tvAk7g6UDU5G1dXrhMa31cKZUB/EkpVe9uCZhdl89NV9f4J1prrZSaatxngft8zQc2KqV2a60P+brWOexV4Fmt9bBS6u8xWv1rTK4pWO3A+HnqU0p9HHgZWBiogyulEoAXgX/UWvf481gBCWqt9VXTva6U+jvgOmCtdnfwTOCXBXZnqsvLfRx3/9mulHoJ49fbCwpqH9QV8POllGpTSmVprVvcv+K1T7EPz/k6rJTajNEa8XVQe/P5Pds0K6UigSSg08d1zLourfX4Gh7H6Ps3W1AucD0+HLXWrymlHlVKpWmt/T5Zk1LKihHST2utfzPJJj49Z6Z3fSilrgHuBdZrrQem2CwoF9hVSsUrpWyexxgXRie9Qh1gZpyvV4DPuB9/Bjin5a+UmqeUinY/TgNWAXV+qMWbzz++3puAjVM0EgJa14R+zPUY/Z9mewX4tHskwwqge1w3l2mUUpme6wpKqeUYeebv/2xxH/MJYJ/W+sdTbObbcxboK6aTXEE9iNGXs9P95bkSnw28NuEq6n6M1tc3A1DXJzD6lYaBNuCPE+vCuHq/y/21N1jqMul8pQJvAQeAN4EU9/ergcfdjy8FdrvP127g836s55zPD3wPo0EAEAM87/75+wCY7+9z5GVdP3D/LO0CNgGlAajpWaAFGHX/bH0e+BLwJffrCnjEXfNuphkFFeC6vjLuXL0PXBqgui7DuDZVOy63Pu7Pcya3kAshRJAzvetDCCHE9CSohRAiyElQCyFEkJOgFkKIICdBLYQQQU6CWgghgpwEtRBCBLn/D+3Yqn5S0bM8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q1_results(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBag5rcAckn8"
   },
   "source": [
    "# Question 2. AVB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-V1V1syvbINX"
   },
   "source": [
    "Here we will implement [Adversairal Variational Bayes](https://dl.acm.org/doi/pdf/10.5555/3305890.3305928).\n",
    "\n",
    "You may experiment with different hyperparameters and architecture designs, but the following designs for the AVB architecture may be useful.\n",
    "\n",
    "```\n",
    "Classifier (T)\n",
    "    Conv2d(1, 32, 3, 1, 1), \n",
    "    ReLU(),\n",
    "    Conv2d(32, 64, 3, 2, 1),\n",
    "    ReLU(), \n",
    "    Conv2d(64, 128, 3, 2, 1), \n",
    "    ReLU(), \n",
    "    Conv2d(128, 128, 3, 2, 1), \n",
    "    ReLU(),\n",
    "    # reshape + add latent\n",
    "    Linear(4 * 4 * 128 + ld, hd), \n",
    "    ReLU(),\n",
    "    Linear(hd, hd), \n",
    "    ReLU(),\n",
    "    Linear(hd, 1)\n",
    "\n",
    "\n",
    "Encoder (E)\n",
    "\n",
    "    Conv2d(1, 32, 3, 1, 1), \n",
    "    ReLU(),\n",
    "    Conv2d(32, 64, 3, 2, 1),\n",
    "    ReLU(), \n",
    "    Conv2d(64, 128, 3, 2, 1), \n",
    "    ReLU(), \n",
    "    Conv2d(128, 128, 3, 2, 1), \n",
    "    ReLU(), \n",
    "    # add noise + reshape\n",
    "    Linear(4 * 4 * 128 + nd, ld)\n",
    "\n",
    "Decoder (D)\n",
    "    ConvTranspose2d(128, 128, 3, 2, 1), \n",
    "    ReLU(), \n",
    "    ConvTranspose2d(128, 64, 4, 2, 1), \n",
    "    ReLU(), \n",
    "    ConvTranspose2d(64, 32, 4, 2, 1), \n",
    "    ReLU(), \n",
    "    Conv2d(32, 1, 3, 1, 1)\n",
    "    # reshape\n",
    "    Linear(ld, 4 * 4 * 128), \n",
    "    ReLU()\n",
    "```\n",
    "\n",
    "**Reminder.** Objective for AVB\n",
    "\n",
    "$$max_{\\theta, \\phi} E \\log p_\\theta(x|z_\\phi(x)) - T(x, z_\\phi(x))$$\n",
    "$$max_{T} E_x \\bigg(E_{q_\\phi(z|x)} \\log\\big(\\sigma (T(x, z))\\big) + E_{p(z)} \\log\\big(1 - \\sigma (T(x, z))\\big)\\bigg) $$\n",
    "\n",
    "$\\phi$ - parameters of encoder, $\\theta$ - parameters of decoder\n",
    "\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the elbo and loss of the classifier T ber batch.\n",
    "2. Report the final test set performances of your final models\n",
    "3. 100 samples from your trained AVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ld):\n",
    "        super().__init__()\n",
    "        self._seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 128, 3, 2, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(128, 128, 3, 2, 1), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self._lin = nn.Linear(4 * 4 * 128 + ld, ld)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        x = self._seq(x)\n",
    "        x = torch.cat([x.reshape(-1, 4 * 4 * 128), z], dim=1)\n",
    "        x = self._lin(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ld):\n",
    "        super().__init__()\n",
    "        self._lin = nn.Linear(ld, 4 * 4 * 128)\n",
    "        self._seq = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 128, 3, 2, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(32, 1, 3, 1, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self._lin(z)\n",
    "        x = x.reshape(-1, 128, 4, 4)\n",
    "        x = self._seq(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, ld):\n",
    "        super().__init__()\n",
    "        self._seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(32, 64, 3, 2, 1),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 128, 3, 2, 1), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(128, 128, 3, 2, 1), \n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        self._out = nn.Sequential(\n",
    "            nn.Linear(4 * 4 * 128 + ld, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, latent):\n",
    "        x = self._seq(x)\n",
    "        x = torch.cat([x.reshape(-1, 4 * 4 * 128), latent], dim=1)\n",
    "        x = self._out(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class AVB(nn.Module):\n",
    "    def __init__(self, hd=256, ld=64):\n",
    "        super().__init__()\n",
    "        self._ld = ld\n",
    "        \n",
    "        self._enc = Encoder(ld)\n",
    "        self._dec = Decoder(ld)\n",
    "        self._clf = Classifier(ld)\n",
    "        \n",
    "        self._dist = dist.Normal(torch.zeros(ld), torch.ones(ld))\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z_p = torch.randn(x.size(0), self._ld, device=x.device)\n",
    "        z_q = self._enc(x, z_p)\n",
    "        \n",
    "        logd_p = self._clf(x, z_p)\n",
    "        logd_q = self._clf(x, z_q)\n",
    "        \n",
    "        d_loss = (1 - logd_p.sigmoid()).log().mean() + logd_q.sigmoid().log().mean()\n",
    "        \n",
    "        rec = self._dec(z_q)\n",
    "        \n",
    "        g_loss = logd_q.mean() - F.binary_cross_entropy_with_logits(rec, x) * x.size(0)\n",
    "        \n",
    "        return d_loss, g_loss\n",
    "        \n",
    "    @torch.no_grad()   \n",
    "    def sample(self, n=100):\n",
    "        z = torch.randn(n, self._ld, device=self.device)\n",
    "        return self._dec(z).sigmoid()  \n",
    "    \n",
    "    def fit(self, train_data, n_epochs=20, lr=1e-3, bs=512):\n",
    "        dl = data.DataLoader(train_data, batch_size=bs, shuffle=True, drop_last=True)\n",
    "        \n",
    "        g_opt = opt.Adam(list(self._enc.parameters()) + list(self._dec.parameters()))\n",
    "        d_opt = opt.Adam(self._clf.parameters())\n",
    "        \n",
    "        g_losses, d_losses = [], []\n",
    "        \n",
    "        bar = tqdm(total=n_epochs * len(dl), desc='Training')\n",
    "        for _ in range(n_epochs):\n",
    "            for batch in dl:\n",
    "                batch = batch.to(self.device)\n",
    "                \n",
    "                d_loss, g_loss = self(batch)\n",
    "                \n",
    "                g_opt.zero_grad()\n",
    "                d_opt.zero_grad()\n",
    "\n",
    "                g_loss.backward(retain_graph=True)\n",
    "                g_opt.step()\n",
    "                \n",
    "                d_loss.backward(retain_graph=True)\n",
    "                d_opt.step()\n",
    "                \n",
    "                g_losses.append(g_loss.item())\n",
    "                d_losses.append(d_loss.item())\n",
    "                \n",
    "                bar.update(1)\n",
    "                bar.set_postfix({'g_loss': g_losses[-1], 'd_loss': d_losses[-1]})\n",
    "                \n",
    "        return np.array(g_losses), np.array(d_losses)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "IFeqntQsUkYG"
   },
   "outputs": [],
   "source": [
    "def q2(train_data, *_, **__):\n",
    "    \"\"\"\n",
    "    train_data - A (n_train, 28, 28, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of elbo_losses evaluated every minibatch\n",
    "    - a (# of training iterations,) numpy array of classifier_losses evaluated every minibatch\n",
    "    - a torch tensor of size (100, 1, 28, 28) of samples with values in {0, 1}\n",
    "    \"\"\"\n",
    "    \n",
    "    model = AVB()\n",
    "    model.to(DEVICE)\n",
    "    model.fit(train_data.transpose(0, 3, 1, 2).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_Kvk3MMY8lH_",
    "outputId": "b97407a1-daa1-4e62-c2a7-9516e4025fd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb96ee197379428c860583d52329be28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/254357716.py\", line 2, in <module>\n",
      "    q2_results(q2)\n",
      "  File \"/Users/dmitry/PycharmProjects/hse_dul/Homework/hw8/dul_2021/utils/hw8_utils.py\", line 89, in q2_results\n",
      "    train_elbo, train_clf, test_elbo, test_clf, samples = q(train_data, test_data)\n",
      "  File \"/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/3636429016.py\", line 12, in q2\n",
      "    model.fit(train_data.transpose(0, 3, 1, 2).astype(np.float32))\n",
      "  File \"/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/4022589288.py\", line 122, in fit\n",
      "    d_loss, g_loss = self(batch)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/4022589288.py\", line 91, in forward\n",
      "    z_q = self._enc(x, z_p)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/4022589288.py\", line 19, in forward\n",
      "    x = self._lin(x)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/Users/dmitry/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/functional.py\", line 1848, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      " (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1634272478997/work/torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2112, 64]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/254357716.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_detect_anomaly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mq2_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/hse_dul/Homework/hw8/dul_2021/utils/hw8_utils.py\u001B[0m in \u001B[0;36mq2_results\u001B[0;34m(q)\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_pickled_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'mnist.pkl'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m     \u001B[0mtrain_elbo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_clf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_elbo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_clf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0mplot_avb_training_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_elbo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_clf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_elbo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_clf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Training Loss'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/3636429016.py\u001B[0m in \u001B[0;36mq2\u001B[0;34m(train_data, *_, **__)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAVB\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_50561/4022589288.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, train_data, n_epochs, lr, bs)\u001B[0m\n\u001B[1;32m    128\u001B[0m                 \u001B[0mg_opt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m                 \u001B[0md_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    131\u001B[0m                 \u001B[0md_opt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2112, 64]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    q2_results(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvY7ZnKOf_p3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Homework8_DRE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hse_dul",
   "language": "python",
   "name": "hse_dul"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}