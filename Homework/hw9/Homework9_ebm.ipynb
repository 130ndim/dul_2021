{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Homework9_ebm.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "hse_dul",
   "language": "python",
   "display_name": "hse_dul"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3b773d1b5fce4f84a78f457a6085232a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_9b743959854a491ea2f12dea121639a7",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_18cb70fd48944e048a98de1d0cba8c0b",
       "IPY_MODEL_bf2d5e18c5284e03afd3247097fa81e6",
       "IPY_MODEL_a412e159e39e4aa0b085427e566d033b"
      ]
     }
    },
    "9b743959854a491ea2f12dea121639a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "18cb70fd48944e048a98de1d0cba8c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8a162751b2e0460d9fa1d50001cce5ff",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d0cde5a1db1e447b8a9c33bfba787901"
     }
    },
    "bf2d5e18c5284e03afd3247097fa81e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_0e088bd654ad40e49b586c7d8ade19d3",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 4680,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 4680,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_766cfcd168d04b2b8039887341bde317"
     }
    },
    "a412e159e39e4aa0b085427e566d033b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_45a2e3275d114895862ea8e00394dd15",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 4680/4680 [12:23&lt;00:00,  6.36it/s, loss=-0.056, c=-0.101, r=0.448]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_615df1868b43425fb5d3d1bc25ec0ce0"
     }
    },
    "8a162751b2e0460d9fa1d50001cce5ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d0cde5a1db1e447b8a9c33bfba787901": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0e088bd654ad40e49b586c7d8ade19d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "766cfcd168d04b2b8039887341bde317": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "45a2e3275d114895862ea8e00394dd15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "615df1868b43425fb5d3d1bc25ec0ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/130ndim/dul_2021/blob/hw9/Homework/hw9/Homework9_ebm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!if [ -d dul_2021 ]; then rm -Rf dul_2021; fi\n",
    "!git clone https://github.com/GrigoryBartosh/dul_2021\n",
    "!pip install ./dul_2021"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ByWitS_XMo8",
    "outputId": "9409e76a-57df-469b-fd60-6e485052f601"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'dul_2021'...\n",
      "remote: Enumerating objects: 303, done.\u001B[K\n",
      "remote: Counting objects: 100% (140/140), done.\u001B[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001B[K\n",
      "remote: Total 303 (delta 80), reused 70 (delta 56), pack-reused 163\u001B[K\n",
      "Receiving objects: 100% (303/303), 54.17 MiB | 41.42 MiB/s, done.\n",
      "Resolving deltas: 100% (137/137), done.\n",
      "Processing ./dul_2021\n",
      "\u001B[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001B[0m\n",
      "Building wheels for collected packages: dul-2021\n",
      "  Building wheel for dul-2021 (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for dul-2021: filename=dul_2021-0.1.0-py3-none-any.whl size=24553 sha256=6787f0aa059821754451c26535dc83090162ba2af4afdf2c2ac692abd9df46e0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-onh0n5ly/wheels/55/59/29/0fb1c635652157734f4d741f32fc11979149684e83e919de06\n",
      "Successfully built dul-2021\n",
      "Installing collected packages: dul-2021\n",
      "Successfully installed dul-2021-0.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from dul_2021.utils.hw9_utils import *"
   ],
   "metadata": {
    "id": "LeFGGzuxB63K"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 1: EBM on MNIST"
   ],
   "metadata": {
    "id": "dFcrPb9xsEN6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we will implement EBM on MNIST data. \n",
    "\n",
    "* **Architecture.** You may experiment with different hyperparameters and architecture designs, but \n",
    "the following designs for the EBM architecture may be useful.\n",
    "\n",
    "```\n",
    "    Conv2d(1, 16, 5, 2, 4), \n",
    "    Swish(),\n",
    "    Conv2d(16, 32, 3, 2, 1),\n",
    "    Swish(), \n",
    "    Conv2d(32, 64, 3, 2, 1), \n",
    "    Swish(), \n",
    "    Conv2d(64, 64, 3, 2, 1), \n",
    "    Swish(),\n",
    "    Flatten(),\n",
    "    Linear(256, 64), \n",
    "    Swish(),\n",
    "    Linear(64, 1)\n",
    "```\n",
    "\n",
    "\n",
    "Where `swish(x) = σ(x)x`. You **should** use activation with non-sparse gradients for better MCMC convergence.\n",
    "\n",
    "* **Buffer.** To use the contrastive divergence objective, we need to generate samples during training. Because of high dimension of image space we need a lot of iterations in MCMC to obtain reasonable samples. We can reduce sampling cost with buffer trick. The idea of this trick it to re-use previous samples as starting points for MCMC (since distribuionts are close). In our implementation, we initialize 95% of starting points with previous samples and 5% with random noise from -1 to 1. \n",
    "\n",
    "* **MCMC.** During MCMC procedure you only need gradients wrt input. You can find it helpful to disable gradients of your model during MCMC. Since all images are in [-1, 1] you should clamp all resulting points during MCMC step. We also clamp gradients to [-0.03, 0.03].\n",
    "    ```\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    ```\n",
    "\n",
    "* **Regularizations.**\n",
    "\n",
    " You should add small noise to real data otherwise ebm will focus on black areas of real images won't train.\n",
    "\n",
    " Add l2 regularaztion to ebm outputs on real and fake data. Otherwise, the output values will fluctuate in a very large range (because energy is invariant to scalar shift).\n",
    "\n",
    "* **Hyperparameters**\n",
    "    * Max buffer size - 8192\n",
    "    * MCMC step size - 10\n",
    "    * MCMC # step - 60\n",
    "    * MCMC noise - N(0, 0.005)\n",
    "    * Noise to data - N(0, 0.005)\n",
    "    * l2 reg weight - 0.1\n",
    "    * batch_size - 128\n",
    "    * use Adam with lr=1e-3 and betas=(0, 0.999)\n",
    "    * you can exponential scheduler\n",
    "    * 20 epochs should be enough (~1 hour on gpu)\n",
    "\n",
    "\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the regularization and contrastive losses per batch.\n",
    "2. 100 samples from your trained EBM"
   ],
   "metadata": {
    "id": "vBkH8uuiywTC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, TYPE_CHECKING\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Module, Conv2d, SiLU as Swish, Sequential as Seq, Linear, Flatten, functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import numpy.typing as npt"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "go4dyBt2F7GT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "id": "QveGR2uwGMLG"
   },
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Buffer:\n",
    "    def __init__(self, img_shape: tuple, size: int = 8192) -> None:\n",
    "        self._size = size\n",
    "        self._elements = torch.rand((size,) + img_shape) * 2 - 1\n",
    "\n",
    "        self._last = 0\n",
    "        self._num_samples = 0\n",
    "\n",
    "    def put(self, img: torch.Tensor) -> None:\n",
    "        B = img.size(0)\n",
    "        self._num_samples = min(self._size, self._num_samples + B)\n",
    "\n",
    "        new_last = self._last + B\n",
    "        if new_last > self._size:\n",
    "            s = self._size - self._last\n",
    "            self._elements[-s:] = img[:s]\n",
    "            self._elements[:B - s] = img[s:]\n",
    "        else:\n",
    "            self._elements[self._last:new_last] = img\n",
    "\n",
    "        self._last = new_last % self._size\n",
    "\n",
    "    def get(self, n_elements: int) -> torch.Tensor:\n",
    "        return self._elements[\n",
    "            torch.from_numpy(np.random.choice(self._num_samples, n_elements, replace=False))\n",
    "        ]\n",
    "\n",
    "    def size(self) -> int:\n",
    "        return self._num_samples\n",
    "\n",
    "    @property\n",
    "    def img_shape(self) -> Tuple[int]:\n",
    "        return tuple(self._elements.size()[1:])"
   ],
   "metadata": {
    "id": "xzOJINiIIxk1"
   },
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "class EBM(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            energy: Module,\n",
    "            buffer: Buffer,\n",
    "            reg_coeff: float = 0.1,\n",
    "            buf_samples_ratio: float = 0.05,\n",
    "            mcmc_n_steps: int = 60,\n",
    "            mcmc_step_size: float = 10.0,\n",
    "            mcmc_noise: float = 5e-3,\n",
    "            data_noise: float = 5e-3,\n",
    "            clip_sample: Tuple[float, float] = (-1.0, 1.0)\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._energy = energy\n",
    "        self._buffer = buffer\n",
    "        self._reg_coeff = reg_coeff\n",
    "        self._buf_samples_ratio = buf_samples_ratio\n",
    "        self._mcmc_n_steps = mcmc_n_steps\n",
    "        self._mcmc_step_size = mcmc_step_size\n",
    "        self._mcmc_noise = mcmc_noise\n",
    "        self._data_noise = data_noise\n",
    "        self._clip_sample = clip_sample\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self._energy.parameters()).device\n",
    "\n",
    "    def _enable_model_grads(self) -> None:\n",
    "        for p in self._energy.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def _disable_model_grads(self) -> None:\n",
    "        for p in self._energy.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def E(self, input: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        return self._energy(input)\n",
    "\n",
    "    def mcmc(self, n: int, n_steps: Optional[int] = None, **kwargs) -> torch.Tensor:\n",
    "        self._disable_model_grads()\n",
    "\n",
    "        n_buffer_samples = int(self._buf_samples_ratio * n)\n",
    "\n",
    "        if self._buffer.size() < n_buffer_samples:\n",
    "            buffer_samples = \\\n",
    "                torch.rand((n_buffer_samples, *self._buffer.img_shape), device=self.device) * 2 - 1\n",
    "        else:\n",
    "            buffer_samples = self._buffer.get(n_buffer_samples).to(self.device)\n",
    "\n",
    "        samples = torch.cat([\n",
    "            buffer_samples,\n",
    "            torch.rand((n - n_buffer_samples, *self._buffer.img_shape), device=self.device) * 2 - 1],\n",
    "            dim=0,\n",
    "        ).requires_grad_()\n",
    "\n",
    "        eps = self._mcmc_step_size\n",
    "        n_steps = n_steps or self._mcmc_n_steps\n",
    "        for step in range(n_steps):\n",
    "            z = torch.randn_like(samples) * self._mcmc_noise\n",
    "            eps -= self._mcmc_step_size / n_steps\n",
    "            eps = max(eps, 1e-6)\n",
    "\n",
    "            g = torch.autograd.grad(self.E(samples, **kwargs).sum(), samples)[0].clamp(-0.03, 0.03)\n",
    "            samples = (samples + z * (2 * eps) ** 0.5 + eps * g).clamp(*self._clip_sample)\n",
    "\n",
    "        self._buffer.put(samples.detach().cpu())\n",
    "        self._enable_model_grads()\n",
    "        return samples\n",
    "\n",
    "    def _compute_energies(self, real: torch.Tensor):\n",
    "        batch = torch.cat(\n",
    "            [real + torch.randn_like(real) * self._data_noise,\n",
    "             self.mcmc(real.size(0))],\n",
    "            dim=0\n",
    "        )\n",
    "        r_es, m_es = self.E(batch).chunk(2)\n",
    "        return r_es, m_es\n",
    "\n",
    "    def _compute_loss(self, real: torch.Tensor, label: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        r_es, m_es = self._compute_energies(real)\n",
    "\n",
    "        c_term = m_es.mean() - r_es.mean()\n",
    "        r_term = (r_es.pow(2) + m_es.pow(2)).mean()\n",
    "\n",
    "        loss = c_term + self._reg_coeff * r_term\n",
    "        return {'loss': loss, 'c_term': c_term, 'r_term': r_term}\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            dl: DataLoader,\n",
    "            num_epochs: int = 20,\n",
    "            lr: float = 1e-3,\n",
    "            betas: Tuple[float, float] = (0.0, 0.999),\n",
    "    ) -> List[Dict[str, float]]:\n",
    "        log = []\n",
    "\n",
    "        opt = Adam(self.parameters(), lr=lr, betas=betas)\n",
    "        with tqdm(total=num_epochs * len(dl)) as pbar:\n",
    "            for epoch in range(num_epochs):\n",
    "                for batch in dl:\n",
    "                    x, y = batch\n",
    "                    loss_dict = self._compute_loss(x.to(self.device), y.to(self.device))\n",
    "\n",
    "                    opt.zero_grad()\n",
    "                    loss_dict['loss'].backward()\n",
    "                    opt.step()\n",
    "\n",
    "                    loss_dict = {k: round(v.item(), 4) for k, v in loss_dict.items()}\n",
    "\n",
    "                    log.append(loss_dict)\n",
    "\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix(loss_dict)\n",
    "\n",
    "        return log"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "83V8vCWcF7GW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def q1(train_data):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 1, 28, 28) torchvision dataset of MNIST images with values from -1 to 1\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array full of contrastive losses on each iteration\n",
    "    - a (# of training iterations, ) numpy array full of regularization losses on each iteration\n",
    "    - a (100, 28, 28, 1) numpy array of 100 samples from ebm model\n",
    "    \"\"\"\n",
    "    dl = DataLoader(train_data, batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "\n",
    "    ebm = EBM(\n",
    "        energy=Seq(\n",
    "            Conv2d(1, 16, 5, 2, 4),\n",
    "            Swish(),\n",
    "            Conv2d(16, 32, 3, 2, 1),\n",
    "            Swish(),\n",
    "            Conv2d(32, 64, 3, 2, 1),\n",
    "            Swish(),\n",
    "            Conv2d(64, 64, 3, 2, 1),\n",
    "            Swish(),\n",
    "            Flatten(),\n",
    "            Linear(256, 64),\n",
    "            Swish(),\n",
    "            Linear(64, 1)\n",
    "        ),\n",
    "        buffer=Buffer(tuple(train_data[0][0].size())),\n",
    "    )\n",
    "    ebm.to(DEVICE)\n",
    "    log = ebm.fit(dl, num_epochs=10)\n",
    "\n",
    "    c_losses, r_losses = zip(*((d['c_term'], d['r_term']) for d in log))\n",
    "\n",
    "    samples = ebm.mcmc(100).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "    return np.array(c_losses), np.array(r_losses), samples"
   ],
   "metadata": {
    "id": "5f89iZY4o4ZF"
   },
   "execution_count": 143,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q1_results(q1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885,
     "referenced_widgets": [
      "3b773d1b5fce4f84a78f457a6085232a",
      "9b743959854a491ea2f12dea121639a7",
      "18cb70fd48944e048a98de1d0cba8c0b",
      "bf2d5e18c5284e03afd3247097fa81e6",
      "a412e159e39e4aa0b085427e566d033b",
      "8a162751b2e0460d9fa1d50001cce5ff",
      "d0cde5a1db1e447b8a9c33bfba787901",
      "0e088bd654ad40e49b586c7d8ade19d3",
      "766cfcd168d04b2b8039887341bde317",
      "45a2e3275d114895862ea8e00394dd15",
      "615df1868b43425fb5d3d1bc25ec0ce0"
     ]
    },
    "id": "rH7NPZAw9IRA",
    "outputId": "c83c25bd-9d4c-49ee-fdc6-29a5f848f105"
   },
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4680 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeaddcd2ea65407fa4fde43e0c9e588e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.833333333333334\n",
      "1 9.666666666666668\n",
      "2 9.500000000000002\n",
      "3 9.333333333333336\n",
      "4 9.16666666666667\n",
      "5 9.000000000000004\n",
      "6 8.833333333333337\n",
      "7 8.666666666666671\n",
      "8 8.500000000000005\n",
      "9 8.33333333333334\n",
      "10 8.166666666666673\n",
      "11 8.000000000000007\n",
      "12 7.83333333333334\n",
      "13 7.666666666666673\n",
      "14 7.500000000000006\n",
      "15 7.333333333333339\n",
      "16 7.166666666666672\n",
      "17 7.000000000000005\n",
      "18 6.833333333333338\n",
      "19 6.666666666666671\n",
      "20 6.500000000000004\n",
      "21 6.3333333333333375\n",
      "22 6.1666666666666705\n",
      "23 6.0000000000000036\n",
      "24 5.833333333333337\n",
      "25 5.66666666666667\n",
      "26 5.500000000000003\n",
      "27 5.333333333333336\n",
      "28 5.166666666666669\n",
      "29 5.000000000000002\n",
      "30 4.833333333333335\n",
      "31 4.666666666666668\n",
      "32 4.500000000000001\n",
      "33 4.333333333333334\n",
      "34 4.166666666666667\n",
      "35 4.0\n",
      "36 3.8333333333333335\n",
      "37 3.666666666666667\n",
      "38 3.5000000000000004\n",
      "39 3.333333333333334\n",
      "40 3.1666666666666674\n",
      "41 3.000000000000001\n",
      "42 2.8333333333333344\n",
      "43 2.666666666666668\n",
      "44 2.5000000000000013\n",
      "45 2.333333333333335\n",
      "46 2.1666666666666683\n",
      "47 2.0000000000000018\n",
      "48 1.833333333333335\n",
      "49 1.6666666666666683\n",
      "50 1.5000000000000016\n",
      "51 1.3333333333333348\n",
      "52 1.166666666666668\n",
      "53 1.0000000000000013\n",
      "54 0.8333333333333347\n",
      "55 0.6666666666666681\n",
      "56 0.5000000000000014\n",
      "57 0.3333333333333348\n",
      "58 0.16666666666666816\n",
      "59 1.4988010832439613e-15\n",
      "0 9.833333333333334\n",
      "1 9.666666666666668\n",
      "2 9.500000000000002\n",
      "3 9.333333333333336\n",
      "4 9.16666666666667\n",
      "5 9.000000000000004\n",
      "6 8.833333333333337\n",
      "7 8.666666666666671\n",
      "8 8.500000000000005\n",
      "9 8.33333333333334\n",
      "10 8.166666666666673\n",
      "11 8.000000000000007\n",
      "12 7.83333333333334\n",
      "13 7.666666666666673\n",
      "14 7.500000000000006\n",
      "15 7.333333333333339\n",
      "16 7.166666666666672\n",
      "17 7.000000000000005\n",
      "18 6.833333333333338\n",
      "19 6.666666666666671\n",
      "20 6.500000000000004\n",
      "21 6.3333333333333375\n",
      "22 6.1666666666666705\n",
      "23 6.0000000000000036\n",
      "24 5.833333333333337\n",
      "25 5.66666666666667\n",
      "26 5.500000000000003\n",
      "27 5.333333333333336\n",
      "28 5.166666666666669\n",
      "29 5.000000000000002\n",
      "30 4.833333333333335\n",
      "31 4.666666666666668\n",
      "32 4.500000000000001\n",
      "33 4.333333333333334\n",
      "34 4.166666666666667\n",
      "35 4.0\n",
      "36 3.8333333333333335\n",
      "37 3.666666666666667\n",
      "38 3.5000000000000004\n",
      "39 3.333333333333334\n",
      "40 3.1666666666666674\n",
      "41 3.000000000000001\n",
      "42 2.8333333333333344\n",
      "43 2.666666666666668\n",
      "44 2.5000000000000013\n",
      "45 2.333333333333335\n",
      "46 2.1666666666666683\n",
      "47 2.0000000000000018\n",
      "48 1.833333333333335\n",
      "49 1.6666666666666683\n",
      "50 1.5000000000000016\n",
      "51 1.3333333333333348\n",
      "52 1.166666666666668\n",
      "53 1.0000000000000013\n",
      "54 0.8333333333333347\n",
      "55 0.6666666666666681\n",
      "56 0.5000000000000014\n",
      "57 0.3333333333333348\n",
      "58 0.16666666666666816\n",
      "59 1.4988010832439613e-15\n",
      "0 9.833333333333334\n",
      "1 9.666666666666668\n",
      "2 9.500000000000002\n",
      "3 9.333333333333336\n",
      "4 9.16666666666667\n",
      "5 9.000000000000004\n",
      "6 8.833333333333337\n",
      "7 8.666666666666671\n",
      "8 8.500000000000005\n",
      "9 8.33333333333334\n",
      "10 8.166666666666673\n",
      "11 8.000000000000007\n",
      "12 7.83333333333334\n",
      "13 7.666666666666673\n",
      "14 7.500000000000006\n",
      "15 7.333333333333339\n",
      "16 7.166666666666672\n",
      "17 7.000000000000005\n",
      "18 6.833333333333338\n",
      "19 6.666666666666671\n",
      "20 6.500000000000004\n",
      "21 6.3333333333333375\n",
      "22 6.1666666666666705\n",
      "23 6.0000000000000036\n",
      "24 5.833333333333337\n",
      "25 5.66666666666667\n",
      "26 5.500000000000003\n",
      "27 5.333333333333336\n",
      "28 5.166666666666669\n",
      "29 5.000000000000002\n",
      "30 4.833333333333335\n",
      "31 4.666666666666668\n",
      "32 4.500000000000001\n",
      "33 4.333333333333334\n",
      "34 4.166666666666667\n",
      "35 4.0\n",
      "36 3.8333333333333335\n",
      "37 3.666666666666667\n",
      "38 3.5000000000000004\n",
      "39 3.333333333333334\n",
      "40 3.1666666666666674\n",
      "41 3.000000000000001\n",
      "42 2.8333333333333344\n",
      "43 2.666666666666668\n",
      "44 2.5000000000000013\n",
      "45 2.333333333333335\n",
      "46 2.1666666666666683\n",
      "47 2.0000000000000018\n",
      "48 1.833333333333335\n",
      "49 1.6666666666666683\n",
      "50 1.5000000000000016\n",
      "51 1.3333333333333348\n",
      "52 1.166666666666668\n",
      "53 1.0000000000000013\n",
      "54 0.8333333333333347\n",
      "55 0.6666666666666681\n",
      "56 0.5000000000000014\n",
      "57 0.3333333333333348\n",
      "58 0.16666666666666816\n",
      "59 1.4988010832439613e-15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/625355187.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mq1_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/hse_dul/Homework/hw9/dul_2021/utils/hw9_utils.py\u001B[0m in \u001B[0;36mq1_results\u001B[0;34m(q1)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mq1_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_mnist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m     \u001B[0mcloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[0mplot_q1_training_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/807279888.py\u001B[0m in \u001B[0;36mq1\u001B[0;34m(train_data)\u001B[0m\n\u001B[1;32m     29\u001B[0m     )\n\u001B[1;32m     30\u001B[0m     \u001B[0mebm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mlog\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mebm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0mc_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mr_losses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'c_term'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'r_term'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/3343001129.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dl, num_epochs, lr, betas)\u001B[0m\n\u001B[1;32m     99\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdl\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m                     \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m                     \u001B[0mloss_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m                     \u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/3343001129.py\u001B[0m in \u001B[0;36m_compute_loss\u001B[0;34m(self, real, label)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreal\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m         \u001B[0mr_es\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm_es\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_energies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreal\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m         \u001B[0mc_term\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mm_es\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mr_es\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/3343001129.py\u001B[0m in \u001B[0;36m_compute_energies\u001B[0;34m(self, real)\u001B[0m\n\u001B[1;32m     73\u001B[0m             \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m         )\n\u001B[0;32m---> 75\u001B[0;31m         \u001B[0mr_es\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm_es\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     76\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mr_es\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm_es\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/3343001129.py\u001B[0m in \u001B[0;36mE\u001B[0;34m(self, input, **kwargs)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_energy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmcmc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_steps\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 446\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    447\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    440\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m--> 442\u001B[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    443\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 2: EBM conditional generation"
   ],
   "metadata": {
    "id": "ngk19-Usokks"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we will train EBM jointly with classifier to generate objects conditioned on class labels. ([original paper](https://arxiv.org/pdf/1912.03263.pdf)).\n",
    "\n",
    "* **Theory**. Here we will work with joint distribution on x (data point) and y (label). We will parametrize probability of the pair as follows\n",
    "\n",
    "```\n",
    "p_θ(x, y) = exp(f_θ(x)[y]) / Z(θ)\n",
    "```\n",
    "Where `f(x)[y]` is an y-th output of the classifier model and `Z(θ)` is a normalization constant.\n",
    "\n",
    "We will optimize log-likelihood of train pair:\n",
    "\n",
    "```\n",
    "log p(x, y) = log p(x) + log p(y|x)\n",
    "```\n",
    "\n",
    "Second term corresponds to normal classification loss and we will optimize it with cross entropy. We will optimize first tirm via contrastive divergence. The energy of can be from classifire output : `E(x)=-log ∑ exp(f_θ(x)[y])`.\n",
    "\n",
    "* **Architecture.** We will work with smile dataset and you can use architecture from practice.\n",
    "\n",
    "* **Hyperparameters**\n",
    "    * Max buffer size - 8192\n",
    "    * MCMC step size - 0.1\n",
    "    * MCMC # step - 500 (during final sampling you can increase it)\n",
    "    * MCMC noise - N(0, 0.005)\n",
    "    * Noise to data - None\n",
    "    * l2 reg weight - 0.1\n",
    "    * batch_size - 128\n",
    "    * use Adam with lr=1e-3 and betas=(0, 0.999)\n",
    "    * you can use exponential scheduler\n",
    "    * 100 epochs should be enough (~10 minutes on cpu)\n",
    "\n",
    "\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record loss per batch.\n",
    "3. 300 samples from your trained EBM. First 100 samples should be generated for label 0, next 100 for label 1, and last 100 for label 2"
   ],
   "metadata": {
    "id": "zapL42YYp8zI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "class CondEBM(EBM):\n",
    "    def E(self, input: torch.Tensor, label: Optional[npt.ArrayLike] = None, **kwargs) -> torch.Tensor:\n",
    "        out = self._energy(input)\n",
    "        if label is not None:\n",
    "            return out[..., label]\n",
    "        return out.logsumexp(-1)\n",
    "\n",
    "    def _compute_loss(self, real: torch.Tensor, label: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        loss_dict = super()._compute_loss(real, label)\n",
    "        clf_loss = F.cross_entropy(self._energy(real), label)\n",
    "        loss_dict['loss'] += clf_loss\n",
    "        loss_dict['clf_term'] = clf_loss\n",
    "        return loss_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def q2(train_data, train_labels):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 2) np.array of binary points\n",
    "    train_labels: An (n_train, ) np.array labels (3 classes)\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array full of losses on each iteration\n",
    "    - a (300, 2) numpy array of 300 samples from ebm model (0-99 with label 0; 100-199 with label 1; 200-300 with label 2)\n",
    "    \"\"\"\n",
    "\n",
    "    dl = DataLoader(\n",
    "        TensorDataset(torch.from_numpy(train_data).float(), torch.from_numpy(train_labels)),\n",
    "        batch_size=128, drop_last=True, shuffle=True\n",
    "    )\n",
    "\n",
    "    ebm = CondEBM(\n",
    "        energy=Seq(\n",
    "            Linear(2, 256),\n",
    "            Swish(),\n",
    "            Linear(256, 256),\n",
    "            Swish(),\n",
    "            Linear(256, 3)\n",
    "        ),\n",
    "        buffer=Buffer(train_data.shape[1:]),\n",
    "        mcmc_n_steps=500,\n",
    "        mcmc_step_size=0.1,\n",
    "        data_noise=0.0,\n",
    "        clip_sample=(-3.0, 3.0),\n",
    "    )\n",
    "    ebm.to(DEVICE)\n",
    "    log = ebm.fit(dl, num_epochs=50)\n",
    "    losses = np.array([d['loss'] for d in log])\n",
    "\n",
    "    samples = ebm.mcmc(300, n_steps=1000, label=np.array([0] * 100 + [1] * 100 + [2] * 100)).detach().cpu().numpy()\n",
    "    return losses, samples\n"
   ],
   "metadata": {
    "id": "tDw5zYhdr0BH"
   },
   "execution_count": 146,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q2_results(q2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "CEMsbsP2-5Uz",
    "outputId": "4a1fde77-fa55-4821-f285-6a5e78642d46"
   },
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/150 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f50883bb68af4330bfe0b07994513052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/3552280741.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mq2_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/hse_dul/Homework/hw9/dul_2021/utils/hw9_utils.py\u001B[0m in \u001B[0;36mq2_results\u001B[0;34m(q2)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mq2_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq2_sample_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0mplot_q2_training_plot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/4202791654.py\u001B[0m in \u001B[0;36mq2\u001B[0;34m(train_data, train_labels)\u001B[0m\n\u001B[1;32m     28\u001B[0m     )\n\u001B[1;32m     29\u001B[0m     \u001B[0mebm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m     \u001B[0mlog\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mebm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m     \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'loss'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1209823137.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dl, num_epochs, lr, betas)\u001B[0m\n\u001B[1;32m    101\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdl\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m                     \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m                     \u001B[0mloss_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m                     \u001B[0mopt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1191032145.py\u001B[0m in \u001B[0;36m_compute_loss\u001B[0;34m(self, real, label)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreal\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0mloss_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreal\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0mclf_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcross_entropy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_energy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreal\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mloss_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'loss'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mclf_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1209823137.py\u001B[0m in \u001B[0;36m_compute_loss\u001B[0;34m(self, real, label)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_compute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreal\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 81\u001B[0;31m         \u001B[0mr_es\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mm_es\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_energies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreal\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0mc_term\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mm_es\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mr_es\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1209823137.py\u001B[0m in \u001B[0;36m_compute_energies\u001B[0;34m(self, real)\u001B[0m\n\u001B[1;32m     72\u001B[0m         batch = torch.cat(\n\u001B[1;32m     73\u001B[0m             [real + torch.randn_like(real) * self._data_noise,\n\u001B[0;32m---> 74\u001B[0;31m              self.mcmc(real.size(0))],\n\u001B[0m\u001B[1;32m     75\u001B[0m             \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m         )\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1209823137.py\u001B[0m in \u001B[0;36mmcmc\u001B[0;34m(self, n, n_steps, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0meps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1e-6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m             \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m0.03\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.03\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m             \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msamples\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mz\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m0.5\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0meps\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_clip_sample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_52207/1191032145.py\u001B[0m in \u001B[0;36mE\u001B[0;34m(self, input, label, **kwargs)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mCondEBM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mEBM\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnpt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mArrayLike\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_energy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m...\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/activation.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    382\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 384\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msilu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    385\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    386\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36msilu\u001B[0;34m(input, inplace)\u001B[0m\n\u001B[1;32m   1897\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1898\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msilu_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1899\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msilu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1900\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1901\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bonus : Conditional generation with EBM and classifier.\n",
    "\n",
    "Here you need to generate points conditioned on class on smile dataset with independently trained ebm and classifier. For generation use MCMC with\n",
    "\n",
    "```\n",
    "log p(x|y) ~ log p(x) + log p(y|x)\n",
    "```\n",
    "\n",
    "Where first term is `-E(x)` and second is obtained via backprop from trained classifier."
   ],
   "metadata": {
    "id": "Lh4RFxa6ytf5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def b(train_data, train_labels):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 2) np.array of binary points\n",
    "    train_labels: An (n_train, ) np.array labels (3 classes)\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array full of losses of classfier on each iteration\n",
    "    - a (# of training iterations, ) numpy array full of losses of ebm on each iteration\n",
    "    - a (300, 2) numpy array of 300 samples from ebm model (0-99 with label 0; 100-199 with label 1; 200-300 with label 2)\n",
    "    \"\"\""
   ],
   "metadata": {
    "id": "V3pB997Yrz8P"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "b_results(b)"
   ],
   "metadata": {
    "id": "5UkKBC82KG_O"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}