{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Homework12_semisupervised.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "hse_dul",
   "language": "python",
   "display_name": "hse_dul"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "6473765590874b4daf70259f8418a398": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_14200bd267114a9fbf41029551f941a1",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0750d00cc3e54b9a86dfd37290a481de",
       "IPY_MODEL_fc99a4b7cc9d477b925d63f9c14ddeea",
       "IPY_MODEL_544843f691564352b00f92a330b639ac"
      ]
     }
    },
    "14200bd267114a9fbf41029551f941a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0750d00cc3e54b9a86dfd37290a481de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_474ae4fd17ec424bb9d9fe8769811adb",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Testing: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d86e625bde12446aa50c3c65dc27253f"
     }
    },
    "fc99a4b7cc9d477b925d63f9c14ddeea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_908b49ba59f24a23bd463c3d9a6ca124",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 3525,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 3525,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_be99deaf579f44578f3268c25b29f99c"
     }
    },
    "544843f691564352b00f92a330b639ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_6b1b20af59ec4f04a46b0c5db60424e3",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 3525/3525 [10:16&lt;00:00, 12.28it/s, loss=0.638, acc=0.206]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7a51a87cc4a94953a926305bd20cf8cb"
     }
    },
    "474ae4fd17ec424bb9d9fe8769811adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d86e625bde12446aa50c3c65dc27253f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "908b49ba59f24a23bd463c3d9a6ca124": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "be99deaf579f44578f3268c25b29f99c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6b1b20af59ec4f04a46b0c5db60424e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7a51a87cc4a94953a926305bd20cf8cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/130ndim/dul_2021/blob/hw12/Homework/hw12/Homework12_semisupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "!if [ -d dul_2021 ]; then rm -Rf dul_2021; fi\n",
    "!git clone https://github.com/GrigoryBartosh/dul_2021\n",
    "!pip install ./dul_2021"
   ],
   "metadata": {
    "id": "vEPPrGksax7-",
    "outputId": "83823fc3-4ed0-48c6-a159-ef1c29370b2e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'dul_2021'...\n",
      "remote: Enumerating objects: 384, done.\u001B[K\n",
      "remote: Counting objects: 100% (221/221), done.\u001B[K\n",
      "remote: Compressing objects: 100% (147/147), done.\u001B[K\n",
      "remote: Total 384 (delta 124), reused 101 (delta 67), pack-reused 163\u001B[K\n",
      "Receiving objects: 100% (384/384), 55.90 MiB | 31.43 MiB/s, done.\n",
      "Resolving deltas: 100% (181/181), done.\n",
      "Processing ./dul_2021\n",
      "\u001B[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001B[0m\n",
      "Building wheels for collected packages: dul-2021\n",
      "  Building wheel for dul-2021 (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for dul-2021: filename=dul_2021-0.1.0-py3-none-any.whl size=27640 sha256=4ac6a036d7361707d902883f7d5c7c8cabf15b77270f5b25e9f38fa5490db474\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t8pmfbmo/wheels/55/59/29/0fb1c635652157734f4d741f32fc11979149684e83e919de06\n",
      "Successfully built dul-2021\n",
      "Installing collected packages: dul-2021\n",
      "Successfully installed dul-2021-0.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from dul_2021.utils.hw12_utils import *\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from typing import TypeVar\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TorchModel = TypeVar(\"TorchModel\", bound=nn.Module)"
   ],
   "metadata": {
    "id": "VUu3B_L7azpr"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 1. VAT\n",
    "\n",
    "Here we will implement [VAT](https://arxiv.org/pdf/1704.03976.pdf).\n",
    "\n",
    "* Train labeled data with standatd cross-entropy loss\n",
    "\n",
    "* Use vat regularization for both unlabeled and labeled data\n",
    "\n",
    "* You can use architecture from practice\n",
    "\n",
    "* Dataset comes as pairs `x, y`. `x` is an image from CIFAR10. `y` is a label from `[0, 10]` if datapoint is labeled and `-1` otherwise.\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "* ξ= 10 \n",
    "* lr = 5e-4\n",
    "* num_epochs = 15\n",
    "\n",
    "\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1. Over the course of training, record loss ber batch.\n",
    "2. After each epoch calculate accuracy on test data."
   ],
   "metadata": {
    "id": "qo4zHxLOv5rX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, out_dim=128, hid_dim_full=128):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 4, 1),\n",
    "        )\n",
    "\n",
    "        self.conv_to_fc = 8 * 8 * 4\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.conv_to_fc),\n",
    "            nn.Linear(self.conv_to_fc, hid_dim_full),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim_full, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x)\n",
    "\n",
    "        x = x.view(-1, self.conv_to_fc)\n",
    "        \n",
    "        x = self.seq2(x)\n",
    "\n",
    "        return x.log_softmax(-1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "mulZkz44_BVf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def compute_loss_on_batch(self, x, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict_on_batch(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit(self, train_dl, test_dl, n_epochs=15, lr=5e-4):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        losses, accuracies = [], []\n",
    "        metric_dict = {}\n",
    "\n",
    "        with tqdm(total=(len(train_dl) + len(test_dl)) * n_epochs) as pbar:\n",
    "            for _ in range(n_epochs):\n",
    "                pbar.set_description_str('Training')\n",
    "                self.train()\n",
    "                for batch in train_dl:\n",
    "                    x, y = batch\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                    loss = self.compute_loss_on_batch(x, y)\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    metric_dict['loss'] = loss.item()\n",
    "                    losses.append(metric_dict['loss'])\n",
    "\n",
    "                    pbar.update()\n",
    "                    pbar.set_postfix(metric_dict)\n",
    "\n",
    "                pbar.set_description_str('Testing')\n",
    "                correct, total = 0, 0\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_dl:\n",
    "                        x, y = batch\n",
    "                        x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                        pred = self.predict_on_batch(x).argmax(-1)\n",
    "\n",
    "                        correct += (pred == y).sum().item()\n",
    "                        total += x.size(0)\n",
    "\n",
    "                        pbar.update()\n",
    "\n",
    "                    metric_dict['acc'] = correct / total\n",
    "                    accuracies.append(metric_dict['acc'])\n",
    "                    pbar.set_postfix(metric_dict)\n",
    "\n",
    "        return np.array(losses), np.array(accuracies)\n",
    "\n",
    "\n",
    "class VATReg(nn.Module):\n",
    "    def __init__(self, xi, eps=1.0):\n",
    "        super().__init__()\n",
    "        self._xi = xi\n",
    "        self._eps = eps\n",
    "\n",
    "    def forward(self, model: TorchModel, x: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            p1 = model(x).exp()\n",
    "\n",
    "        d = torch.randn_like(x)\n",
    "        d /= d.view(d.size(0), -1).norm(dim=-1)[:, None, None, None]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        d.requires_grad_()\n",
    "        log_p2 = model(x + self._xi * d)\n",
    "        dist = F.kl_div(log_p2, p1, reduction='batchmean')\n",
    "        dist.backward()\n",
    "\n",
    "        g = d.grad\n",
    "        g /= g.view(g.size(0), -1).norm(dim=-1)[:, None, None, None]\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        log_p3 = model(x + g * self._eps)\n",
    "        model.train()\n",
    "        return F.kl_div(log_p3, p1, reduction='batchmean')\n",
    "\n",
    "\n",
    "class VAT(Model):\n",
    "    def __init__(self, out_dim=10, hidden_dim=128, xi=10.0, eps=1.0):\n",
    "        super().__init__()\n",
    "        self.net = Net(out_dim, hidden_dim)\n",
    "\n",
    "        self.reg = VATReg(xi, eps)\n",
    "\n",
    "    def predict_on_batch(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def compute_loss_on_batch(self, x, y):\n",
    "        mask = y > -1\n",
    "        loss = F.nll_loss(self.net(x[mask]), y[mask]) + self.reg(self.net, x)\n",
    "        return loss\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dcAjG9nE_BVg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def q1(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 3, 32, 32) torchvision dataset of CIFAR10 images with values from -1 to 1\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array  losses on each iteration\n",
    "    - a (# of training epochs, ) numpy array accuracies on each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    train_dl = data.DataLoader(train_data, batch_size=256, drop_last=True, shuffle=True)\n",
    "    test_dl = data.DataLoader(test_data, batch_size=256)\n",
    "\n",
    "    vat = VAT().to(DEVICE)\n",
    "\n",
    "    losses, accuracies = vat.fit(train_dl, test_dl)\n",
    "\n",
    "    return losses, accuracies\n"
   ],
   "metadata": {
    "id": "v3neKPxpZImJ"
   },
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q12_results(q1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639,
     "referenced_widgets": [
      "6473765590874b4daf70259f8418a398",
      "14200bd267114a9fbf41029551f941a1",
      "0750d00cc3e54b9a86dfd37290a481de",
      "fc99a4b7cc9d477b925d63f9c14ddeea",
      "544843f691564352b00f92a330b639ac",
      "474ae4fd17ec424bb9d9fe8769811adb",
      "d86e625bde12446aa50c3c65dc27253f",
      "908b49ba59f24a23bd463c3d9a6ca124",
      "be99deaf579f44578f3268c25b29f99c",
      "6b1b20af59ec4f04a46b0c5db60424e3",
      "7a51a87cc4a94953a926305bd20cf8cb"
     ]
    },
    "id": "saxnnzOCzkMx",
    "outputId": "2c9abbe4-aa3f-4bf1-a44d-8bbaaf42eac8"
   },
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3525 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a4c84e2e9fd424c94beda79d1d8fb96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/4114373277.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mq12_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/hse_dul/Homework/hw12/dul_2021/utils/hw12_utils.py\u001B[0m in \u001B[0;36mq12_results\u001B[0;34m(q)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSSDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSSDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0mplot_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Loss'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/1681235670.py\u001B[0m in \u001B[0;36mq1\u001B[0;34m(train_data, test_data)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mvat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVAT\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracies\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_dl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracies\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/642602460.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, train_dl, test_dl, n_epochs, lr)\u001B[0m\n\u001B[1;32m     24\u001B[0m                     \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m                     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss_on_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/642602460.py\u001B[0m in \u001B[0;36mcompute_loss_on_batch\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcompute_loss_on_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_forward_unimplemented\u001B[0;34m(self, *input)\u001B[0m\n\u001B[1;32m    199\u001B[0m         \u001B[0mregistered\u001B[0m \u001B[0mhooks\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mlatter\u001B[0m \u001B[0msilently\u001B[0m \u001B[0mignores\u001B[0m \u001B[0mthem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \"\"\"\n\u001B[0;32m--> 201\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 2. FixMatch\n",
    "\n",
    "Here we will implement [FixMatch](https://arxiv.org/abs/2001.07685).\n",
    "\n",
    "* Calculate loss on weakly augmented labeled data with standatd cross-entropy loss\n",
    "\n",
    "* Calculate loss on strongly augmented unlabeled data with standatd cross-entropy loss with pseudo-lables\n",
    "\n",
    "* Use SimCLR transformations as strong and RandomHorizontalFlip as weak\n",
    "\n",
    "* You can use architecture from practice\n",
    "\n",
    "* Dataset comes as pairs `x, y`. `x` is an image from CIFAR10. `y` is a label from `[0, 10]` if datapoint is labeled and `-1` otherwise.\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "* τ = 0.7 \n",
    "* λ_u = 10 (weight of unlabeled loss)\n",
    "* lr = 5e-4\n",
    "* num_epochs ~ 20 or more\n",
    "\n",
    "\n",
    "\n",
    "**You will provide the following deliverables**\n",
    "\n",
    "\n",
    "1. Over the course of training, record loss ber batch.\n",
    "2. After each epoch calculate accuracy on test data."
   ],
   "metadata": {
    "id": "zxgc1UFd_cpi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class FixMatchLoss(nn.Module):\n",
    "    def __init__(self, tau=0.7):\n",
    "        super().__init__()\n",
    "        self._tau = tau\n",
    "\n",
    "    def forward(self, logp_w: torch.Tensor, logp_s: torch.Tensor):\n",
    "        mask = (logp_w.exp() >= self._tau).any(-1)\n",
    "        if mask.any():\n",
    "            return F.nll_loss(logp_s[mask], logp_w[mask].argmax(-1))\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class FixMatch(Model):\n",
    "    def __init__(self, output_dim=10, hidden_dim=128, tau=0.7, lambda_u=10.0):\n",
    "        super().__init__()\n",
    "        self.net = Net(output_dim, hidden_dim)\n",
    "\n",
    "        self.loss = FixMatchLoss(tau)\n",
    "        self._lambda_u = lambda_u\n",
    "\n",
    "        self._strong_tf = T.Compose(\n",
    "            [\n",
    "                T.RandomResizedCrop(size=32),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.RandomApply([T.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.Normalize((0.5,) * 3, (0.5,) * 3),\n",
    "            ]\n",
    "        )\n",
    "        self._weak_tf = T.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "    def compute_loss_on_batch(self, x, y):\n",
    "        mask = y > -1\n",
    "        xl, yl, xu = x[mask], y[mask], x[~mask]\n",
    "\n",
    "        xus, xuw = self._strong_tf(xu), self._weak_tf(xu)\n",
    "\n",
    "        logp_l, logp_w, logp_s = self.net(\n",
    "            torch.cat([xl, xuw, xus], dim=0)\n",
    "        ).split((xl.size(0), xuw.size(0), xus.size(0)))\n",
    "\n",
    "        return F.nll_loss(logp_l, yl) + self._lambda_u * self.loss(logp_w, logp_s)\n",
    "\n",
    "    def predict_on_batch(self, x):\n",
    "        return self.net(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def q2(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 3, 32, 32) torchvision dataset of CIFAR10 images with values from -1 to 1\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array  losses on each iteration\n",
    "    - a (# of training epochs, ) numpy array accuracies on each epoch\n",
    "    \"\"\"\n",
    "    train_dl = data.DataLoader(train_data, batch_size=256, drop_last=True, shuffle=True)\n",
    "    test_dl = data.DataLoader(test_data, batch_size=256)\n",
    "\n",
    "    fm = FixMatch().to(DEVICE)\n",
    "\n",
    "    losses, accuracies = fm.fit(train_dl, test_dl, n_epochs=20)\n",
    "\n",
    "    return losses, accuracies"
   ],
   "metadata": {
    "id": "UZGq-KG9abw3"
   },
   "execution_count": 108,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q12_results(q2)"
   ],
   "metadata": {
    "id": "ePG4-hS0abw_"
   },
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4700 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd23097636a5465099b521a3dcf33c11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/3644880613.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mq12_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/hse_dul/Homework/hw12/dul_2021/utils/hw12_utils.py\u001B[0m in \u001B[0;36mq12_results\u001B[0;34m(q)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSSDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSSDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mq\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0mplot_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Loss'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/4010424018.py\u001B[0m in \u001B[0;36mq2\u001B[0;34m(train_data, test_data)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mfm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFixMatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracies\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_dl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracies\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zg/dd_4mghs167bb5hrrgz9w4y40000gn/T/ipykernel_46072/3790223044.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, train_dl, test_dl, n_epochs, lr)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m                     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss_on_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m                     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 307\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/hse_dul/lib/python3.9/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "mzVcaBqkdd6s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bonus\n",
    "\n",
    "## The probabilistic model\n",
    "\n",
    "*(this is a short summary of the model presented in [\"Semi-supervised Learning with\n",
    "Deep Generative Models\"](https://arxiv.org/pdf/1406.5298.pdf))*\n",
    "\n",
    "In the semi-supervised setting, the generative model is a little more complicated than vanilla VAE. In particular, it incorporates a new variable $y$ that represents the class of a digit $x$.\n",
    "\n",
    "\\begin{align*}\n",
    "& p(x, y, z) = p(x \\mid y, z) p(z) p(y) \\\\\n",
    "& p(y) = Cat(y \\mid \\pi_0), \\pi_0 = (1/10, \\dots, 1/10) \\\\\n",
    "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
    "& p(x \\mid y, z) = \\prod_{i=1}^D p_i(y, z)^{x_i} (1 - p_i(y, z))^{1 - x_i}\n",
    "\\end{align*}\n",
    "\n",
    "## The first part of the objective\n",
    "\n",
    "Whenever we train a probabilistic model with partial observations, we interpret the unobserved variables as latent variables. Then we marginalize them. In this case, the loss function splits into two terms: one for observed variables (we denote the set of indices of observed labels $P$), another for unobserved.\n",
    "\n",
    "\\begin{equation}\n",
    "L(X, y) = \\sum_{i \\notin P} \\log p(x_i) + \\sum_{i \\in P} \\log p(x_i, y_i)\n",
    "\\end{equation}\n",
    "\n",
    "Again, we can't compute the exact values of marginal likelihoods and resort to variational lower bound on likelihood. To compute lower bounds, we define the following variational approximation:\n",
    "\n",
    "\\begin{align*}\n",
    "& q(y, z \\mid x) = q(y \\mid x) q(z \\mid y, x)\\\\\n",
    "& \\\\\n",
    "& q(y \\mid x) = Cat(y \\mid \\pi(x))\\\\\n",
    "& q(z \\mid y, x) = \\mathcal N(z \\mid \\mu_\\phi(x, y), \\operatorname{diag}\\sigma^2_\\phi(y, x))\n",
    "\\end{align*}\n",
    "\n",
    "Using the variational approximation, we will obtain two lower bounds.\n",
    "\n",
    "First, the ELBO for $\\log p(x_i, y_i)$ for the observed variables (this one is similar to ELBO of VAE).\n",
    "\n",
    "\\begin{equation}\n",
    "\\log p(x, y) = \\log \\mathbb E_{p(z)} p(x, y \\mid z) \\geq \\mathbb E_{q(z \\mid y, x)} \\log \\frac{p(x, y \\mid z) p(z)}{q(z \\mid y, x)}\n",
    "\\end{equation}\n",
    "\n",
    "Second, the ELBO for $\\log p(x_i)$ for the unobserved variables.\n",
    "\n",
    "\\begin{equation}\n",
    "\\log p(x) = \\log \\mathbb E_{p(y)} \\mathbb E_{p(z \\mid y)} \\log p(x\\mid z, y)\\geq \\mathbb E_{q(y \\mid x)} \\mathbb E_{q(z \\mid y, x)} \\log \\frac{p(x, y \\mid z) p(z)}{q(z \\mid y, x) q(y \\mid x)}\n",
    "\\end{equation}\n",
    "\n",
    "Finally, the joint lower bound will be\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal L(X, y) = \\sum_{i \\in P} \\mathbb E_{q(z_i \\mid y_i, x_i)} \\log \\frac{p(x_i, y_i \\mid z_i) p(z_i)}{q(z_i \\mid y_i, x_i)} + \\sum_{i \\notin P} \\mathbb E_{q(y_i \\mid x_i)} \\mathbb E_{q(z_i \\mid y_i, x_i)} \\log \\frac{p(x_i, y_i \\mid z_i) p(z_i)}{q(z_i \\mid y_i, x_i) q(y_i \\mid x_i)}\n",
    "\\end{equation}\n",
    "\n",
    "We will use reparametrized Monte-Carlo estimates to approximate expectation w.r.t. $z$. To approximate expectaion w.r.t. the discrete variable $y$ we will try three different options."
   ],
   "metadata": {
    "id": "70Ckao5QSblC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def b(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: An (n_train, 1, 28, 28) torchvision dataset of binary MNIST images\n",
    "    Returns\n",
    "    - a (# of training iterations, ) numpy array  losses on each iteration\n",
    "    - a (# of training epochs, ) numpy array accuracies on each epoch\n",
    "    \"\"\""
   ],
   "metadata": {
    "id": "opRfI5beScTp"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}